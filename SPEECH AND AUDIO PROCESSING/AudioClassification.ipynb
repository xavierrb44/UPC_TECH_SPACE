{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AudioClassification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROyb8uauZFb3"
      },
      "source": [
        "# Audio Classification with Mel-Spectrogram filterbanks\n",
        "\n",
        "For this tutorial we will use the audio samples from Google Speech Commands Dataset v0.01 https://www.kaggle.com/c/tensorflow-speech-recognition-challenge/data\n",
        "\n",
        "The audio samples consist of recordings of simple commands of duration of 1 second. Twenty core command words were recorded, with most speakers saying each of them five times. \n",
        "The core words are\n",
        "\"Yes\", \"No\", \"Up\", \"Down\", \"Left\", \"Right\", \"On\", \"Off\", \"Stop\", \"Go\", \"Zero\", \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", and \"Nine\". \n",
        "\n",
        "To help distinguish unrecognized words, there are also ten auxiliary words, which most speakers only said once. These include \"Bed\", \"Bird\", \"Cat\", \"Dog\", \"Happy\", \"House\", \"Marvin\", \"Sheila\", \"Tree\", and \"Wow\".\n",
        "\n",
        "There is also long samples of background noise / silence.\n",
        "\n",
        "For convenience, three list of files are provided for train/validation/test splits.\n",
        "\n",
        "First let's download and extract the database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH0Q9Xm12Jgg"
      },
      "source": [
        "import io\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms, datasets\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import os.path\n",
        "import pickle\n",
        "import hashlib\n",
        "import librosa\n",
        "from scipy.io import wavfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-Cu_keatsgk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0bece28-6fcb-4fd5-e15b-24008f5a25db"
      },
      "source": [
        "!pip install torchsummary\n",
        "#example https://poutyne.org/examples/introduction.html\n",
        "!pip install poutyne"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "Collecting poutyne\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/b8/0dfe01433c3fe1d14cdccb5b4456085ea60a788de9d8efa5c447cae30417/Poutyne-1.3-py3-none-any.whl (133kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from poutyne) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from poutyne) (1.19.5)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch->poutyne) (0.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->poutyne) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch->poutyne) (0.16.0)\n",
            "Installing collected packages: poutyne\n",
            "Successfully installed poutyne-1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz65D-Ef-MON",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5a56ad5-5726-4c63-ffce-7fbee7ba1b6d"
      },
      "source": [
        "!pip install gdown\n",
        "!gdown \"https://drive.google.com/uc?id=1HR28jRFwrveq5zxjkzri61jm9F4-M7p7\"\n",
        "!tar -zxf speech_commands_v0.01_with_splits.tar.gz\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2020.12.5)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HR28jRFwrveq5zxjkzri61jm9F4-M7p7\n",
            "To: /content/speech_commands_v0.01_with_splits.tar.gz\n",
            "1.49GB [00:24, 60.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpQmJqxMbwCw"
      },
      "source": [
        "# Define Class for computing Mel-Spectrogram\n",
        "\n",
        "As seen in previous colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTiLABiib7cd"
      },
      "source": [
        "#Helper Functions borrowed from torchaudio https://github.com/pytorch/audio/blob/master/torchaudio/transforms.py\n",
        "\n",
        "class PadTrim(object):\n",
        "    \"\"\"Pad/Trim a 1d-Tensor (Signal or Labels)\n",
        "    Args:\n",
        "        tensor (Tensor): Tensor of audio of size (n x c) or (c x n)\n",
        "        max_len (int): Length to which the tensor will be padded\n",
        "        channels_first (bool): Pad for channels first tensors.  Default: `True`\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, max_len, fill_value=0, channels_first=True):\n",
        "        self.max_len = max_len\n",
        "        self.fill_value = fill_value\n",
        "        self.len_dim, self.ch_dim = int(channels_first), int(not channels_first)\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            Tensor: (c x n) or (n x c)\n",
        "        \"\"\"\n",
        "        assert tensor.size(self.ch_dim) < 128, \\\n",
        "            \"Too many channels ({}) detected, see channels_first param.\".format(tensor.size(self.ch_dim))\n",
        "        if self.max_len > tensor.size(self.len_dim):\n",
        "            padding = [self.max_len - tensor.size(self.len_dim)\n",
        "                       if (i % 2 == 1) and (i // 2 != self.len_dim)\n",
        "                       else 0\n",
        "                       for i in range(4)]\n",
        "            with torch.no_grad():\n",
        "                tensor = torch.nn.functional.pad(tensor, padding, \"constant\", self.fill_value)\n",
        "        elif self.max_len < tensor.size(self.len_dim):\n",
        "            tensor = tensor.narrow(self.len_dim, 0, self.max_len)\n",
        "        return tensor\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(max_len={0})'.format(self.max_len)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class MelScale(object):\n",
        "    \"\"\"This turns a normal STFT into a mel frequency STFT, using a conversion\n",
        "       matrix.  This uses triangular filter banks.\n",
        "    Args:\n",
        "        n_mels (int): number of mel bins\n",
        "        sr (int): sample rate of audio signal\n",
        "        f_max (float, optional): maximum frequency. default: `sr` // 2\n",
        "        f_min (float): minimum frequency. default: 0\n",
        "        n_stft (int, optional): number of filter banks from stft. Calculated from first input\n",
        "            if `None` is given.  See `n_fft` in `Spectrogram`.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_mels=128, sr=16000, f_max=None, f_min=0., n_stft=None):\n",
        "        self.n_mels = n_mels\n",
        "        self.sr = sr\n",
        "        self.f_max = f_max if f_max is not None else sr // 2\n",
        "        self.f_min = f_min\n",
        "        self.fb = self._create_fb_matrix(n_stft) if n_stft is not None else n_stft\n",
        "\n",
        "    def __call__(self, spec_f):\n",
        "        if self.fb is None:\n",
        "            self.fb = self._create_fb_matrix(spec_f.size(2)).to(spec_f.device)\n",
        "        else:\n",
        "            # need to ensure same device for dot product\n",
        "            self.fb = self.fb.to(spec_f.device)\n",
        "        spec_m = torch.matmul(spec_f, self.fb)  # (c, l, n_fft) dot (n_fft, n_mels) -> (c, l, n_mels)\n",
        "        return spec_m\n",
        "\n",
        "    def _create_fb_matrix(self, n_stft):\n",
        "        \"\"\" Create a frequency bin conversion matrix.\n",
        "        Args:\n",
        "            n_stft (int): number of filter banks from spectrogram\n",
        "        \"\"\"\n",
        "\n",
        "        # get stft freq bins\n",
        "        stft_freqs = torch.linspace(self.f_min, self.f_max, n_stft)\n",
        "        # calculate mel freq bins\n",
        "        m_min = 0. if self.f_min == 0 else self._hertz_to_mel(self.f_min)\n",
        "        m_max = self._hertz_to_mel(self.f_max)\n",
        "        m_pts = torch.linspace(m_min, m_max, self.n_mels + 2)\n",
        "        f_pts = self._mel_to_hertz(m_pts)\n",
        "        # calculate the difference between each mel point and each stft freq point in hertz\n",
        "        f_diff = f_pts[1:] - f_pts[:-1]  # (n_mels + 1)\n",
        "        slopes = f_pts.unsqueeze(0) - stft_freqs.unsqueeze(1)  # (n_stft, n_mels + 2)\n",
        "        # create overlapping triangles\n",
        "        z = torch.tensor(0.)\n",
        "        down_slopes = (-1. * slopes[:, :-2]) / f_diff[:-1]  # (n_stft, n_mels)\n",
        "        up_slopes = slopes[:, 2:] / f_diff[1:]  # (n_stft, n_mels)\n",
        "        fb = torch.max(z, torch.min(down_slopes, up_slopes))\n",
        "        return fb\n",
        "\n",
        "    def _hertz_to_mel(self, f):\n",
        "        return 2595. * torch.log10(torch.tensor(1.) + (f / 700.))\n",
        "\n",
        "    def _mel_to_hertz(self, mel):\n",
        "        return 700. * (10**(mel / 2595.) - 1.)\n",
        "      \n",
        "class MelSpectrogram(nn.Module):\n",
        "    def __init__(self, n_mels = 40, sfr=16000):\n",
        "        super(MelSpectrogram, self).__init__()\n",
        "        self.sfr = sfr\n",
        "        self.window_stride=0.01\n",
        "        self.window_size=0.02\n",
        "        self.n_fft=512\n",
        "        self.n_mels=n_mels\n",
        "        \n",
        "        self.win_length = int(self.sfr * self.window_size)\n",
        "        self.hop_length = int(self.sfr * self.window_stride)\n",
        "        self.lowfreq = 20\n",
        "        self.highfreq = self.sfr/2 - 400\n",
        "        self.window = torch.hamming_window(self.win_length).cuda()\n",
        "        \n",
        "        self.mel = MelScale(n_mels=self.n_mels, sr=self.sfr, f_max=self.highfreq, f_min=self.lowfreq)\n",
        "        self.norm = nn.InstanceNorm2d(1)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        \n",
        "        x = x.squeeze(1)\n",
        "        spec_f = torch.stft(x, n_fft=self.n_fft, hop_length=self.hop_length, \n",
        "                    win_length=self.win_length, \n",
        "                    window=self.window,\n",
        "                    center=True,\n",
        "                    normalized=False, onesided=True,\n",
        "                    pad_mode='reflect'\n",
        "                   )\n",
        "        spec_f = spec_f.pow(2).sum(-1)\n",
        "        x = self.mel(spec_f.transpose(1,2)).transpose(1,2)\n",
        "        x = torch.log(x+0.0001)\n",
        "        x = x.unsqueeze(1)\n",
        "        #x = self.norm(x)\n",
        "        return x\n",
        "      \n",
        "      \n",
        "    def plot_sample(self, fbank, index):\n",
        "        librosa.display.specshow(fbank[index,:,:,:].view(self.n_mels,-1).numpy(),\n",
        "                          y_axis='mel', x_axis='time',sr=self.sfr, fmax=self.highfreq, hop_length=self.hop_length)\n",
        "        plt.title('Mel spectrogram')\n",
        "        plt.colorbar(format='%+2.0f dB')\n",
        "        plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y-K1ePceHot"
      },
      "source": [
        "#AudioReader for wavefiles\n",
        "\n",
        "This reader provides data in the format X, Y = (raw_audio, target_class)\n",
        "\n",
        "**add_silence_class** parameter: includes random samples from background noise to the dataset in the sample proportion as the \"yes\" class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdwsRHAH4VJj"
      },
      "source": [
        "class AudioReader(data.Dataset):\n",
        "  \n",
        "    def __init__(self, list_path, transform=PadTrim(16000), add_silence_class=False, add_noise=False):\n",
        "        \n",
        "        self.list_path = list_path\n",
        "        self.database_path = os.path.dirname(list_path) + '/audio/'\n",
        "        self.add_noise = add_noise\n",
        "        self.add_silence_class = add_silence_class\n",
        "        self.transform = transform\n",
        "\n",
        "        self.target_class = {}\n",
        "        self.target_class_idx_to_name = {}\n",
        "        self.target_class_names = ['unknown','silence', 'yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
        "        for i, name in enumerate(self.target_class_names):\n",
        "            self.target_class[name] = i\n",
        "            self.target_class_idx_to_name[i] = name\n",
        "        self.audio_class = {}\n",
        "        self.audio_speaker = {}\n",
        "        self.audios = []\n",
        "                 \n",
        "        self.read_list_data()\n",
        "                 \n",
        "        self.speaker_ids = {}\n",
        "        for i, spk_id in enumerate(self.audio_speaker.values()):\n",
        "            self.speaker_ids[spk_id] = i\n",
        "        \n",
        "        \n",
        "        self.num_silence = 0\n",
        "        \n",
        "        if self.add_noise or self.add_silence_class:\n",
        "            self.background_noises_names = []\n",
        "            self.background_noises = []\n",
        "            for f in os.listdir(self.database_path + '/_background_noise_/'):\n",
        "                if f.endswith(\".wav\"):\n",
        "                    self.background_noises_names.append('_background_noise_/' + f)\n",
        "                    print(self.background_noises_names[-1])\n",
        "                    self.background_noises.append( self.load_audio(self.background_noises_names[-1]))\n",
        "\n",
        "                    \n",
        "        if self.add_silence_class:  #Adding the same amount of samples as the \"yes\" class\n",
        "            self.num_silence = sum(1 for i in self.audio_class.values() if i == 'yes')\n",
        "            \n",
        "        self.seeded = False\n",
        "        \n",
        "        \n",
        "    \n",
        "    def read_list_data(self):\n",
        "        with open(self.list_path, 'r') as stream:\n",
        "            for line in stream:\n",
        "                file_path = line.strip()\n",
        "                file_class, file_name = file_path.split('/')\n",
        "                identity = file_name.split('_')[0]\n",
        "                self.audio_class[file_path] = file_class\n",
        "                self.audio_speaker[file_path] = identity\n",
        "                self.audios.append(file_path)\n",
        "                \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.audio_class) + self.num_silence\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        if not self.seeded:\n",
        "            self.seeded = True\n",
        "            np.random.seed(index)\n",
        "            \n",
        "        if index >= len(self.audios):\n",
        "            spk_id=-1\n",
        "            length = 16000\n",
        "            audio = self.get_silence_chunk(length)\n",
        "            target_id = self.target_class['silence']\n",
        "            audio_id = 'random_silence/randomchunk.wav' \n",
        "        else:\n",
        "          \n",
        "            audio_id = self.audios[index]\n",
        "            audio = self.load_audio(audio_id)\n",
        "      \n",
        "            spk_id = self.speaker_ids[self.audio_speaker[audio_id]]\n",
        "            target = self.audio_class[audio_id]\n",
        "      \n",
        "            if target not in self.target_class_names:\n",
        "                target = 'unknown'\n",
        "            target_id = self.target_class[target]\n",
        "            \n",
        "        audio -= audio.mean()\n",
        "        #max_val = np.abs(audio[np.argpartition(np.abs(audio),-10)[-10:]]).mean()\n",
        "        max_val = np.abs(audio).max()\n",
        "        audio /= max_val + 0.001    \n",
        "            \n",
        "        sample = torch.FloatTensor(audio)\n",
        "        if self.add_noise:\n",
        "            alpha = np.random.uniform(low=0.90, high=1.00)\n",
        "            beta = 1.0 - alpha\n",
        "            silence_chunk = self.get_silence_chunk(len(audio))\n",
        "            max_val = np.abs(silence_chunk).max()\n",
        "            silence_chunk /= max_val + 0.001    \n",
        "            sample_noise = torch.FloatTensor(audio * alpha + beta * silence_chunk)\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            sample = sample.view(1,-1)\n",
        "            sample = self.transform(sample)\n",
        "            if self.add_noise:\n",
        "                sample_noise = sample_noise.view(1,-1)\n",
        "                sample_noise = self.transform(sample_noise)\n",
        "              \n",
        "            \n",
        "        if self.add_noise:\n",
        "            return sample_noise,  target_id\n",
        "        else:\n",
        "            return sample, target_id\n",
        "        \n",
        "    def load_audio(self, audio_name):\n",
        "        \n",
        "        audio_path = self.database_path + audio_name\n",
        "        fs, audio = wavfile.read(audio_path)\n",
        "        audio = audio / 2**15\n",
        "        #audio, fs = librosa.load(audio_path)\n",
        "\n",
        "        return audio\n",
        "                 \n",
        "    \n",
        "    \n",
        "    def get_silence_chunk(self, length):\n",
        "        i = np.random.randint(0, len(self.background_noises))\n",
        "        silence = self.background_noises[i]\n",
        "        max_start = silence.shape[0] - length -1\n",
        "        random_start = np.random.randint(0, max_start)\n",
        "        #print(\"Starting at\", random_start )\n",
        "        chunk = silence[random_start:(random_start + length)]\n",
        "        return chunk\n",
        "      \n",
        "    def get_class_weights(self):\n",
        "        class_ids = []\n",
        "        for target in self.audio_class.values():\n",
        "            if target not in self.target_class_names:\n",
        "                target = 'unknown'\n",
        "            target_id = self.target_class[target]\n",
        "            class_ids.append(target_id)\n",
        "        for jj in range(self.num_silence):\n",
        "            class_ids.append(self.target_class['silence'])\n",
        "        class_ids.append(self.target_class['unknown'])\n",
        "        from sklearn.utils import class_weight\n",
        "        #print(np.unique(class_ids))\n",
        "        class_weight = class_weight.compute_class_weight('balanced', np.unique(class_ids),class_ids)\n",
        "        class_weight = torch.from_numpy(class_weight).float()\n",
        "        return class_weight\n",
        "      \n",
        "    def get_n_classes(self):\n",
        "        return len(self.target_class_names)\n",
        "     \n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myp0dMin9tIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c98eefac-2a55-4553-ce5f-a8ba47d30f10"
      },
      "source": [
        "train_loader = data.DataLoader(\n",
        "                    AudioReader('gcommands/training_list.txt',add_silence_class=True), \n",
        "                        batch_size=50, shuffle=True, num_workers=2, pin_memory=True, \n",
        "                    )\n",
        "\n",
        "train_loader_noise = data.DataLoader(\n",
        "                    AudioReader('gcommands/training_list.txt',add_silence_class=True, add_noise=True), \n",
        "                        batch_size=50, shuffle=True, num_workers=2, pin_memory=True, \n",
        "                    )\n",
        "\n",
        "valid_loader = data.DataLoader(\n",
        "                    AudioReader('gcommands/validation_list.txt'), \n",
        "                        batch_size=50, shuffle=False, num_workers=2, pin_memory=True, \n",
        "                    )\n",
        "\n",
        "test_loader = data.DataLoader(\n",
        "                    AudioReader('gcommands/testing_list.txt'), \n",
        "                        batch_size=50, shuffle=False, num_workers=2, pin_memory=True, \n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_background_noise_/exercise_bike.wav\n",
            "_background_noise_/pink_noise.wav\n",
            "_background_noise_/running_tap.wav\n",
            "_background_noise_/dude_miaowing.wav\n",
            "_background_noise_/doing_the_dishes.wav\n",
            "_background_noise_/white_noise.wav\n",
            "_background_noise_/exercise_bike.wav\n",
            "_background_noise_/pink_noise.wav\n",
            "_background_noise_/running_tap.wav\n",
            "_background_noise_/dude_miaowing.wav\n",
            "_background_noise_/doing_the_dishes.wav\n",
            "_background_noise_/white_noise.wav\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:116: WavFileWarning: Chunk (non-data) not understood, skipping it.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g3Prx-aHO6T"
      },
      "source": [
        "\n",
        "for batch in train_loader:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-O7ZJPqJWB6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08b8fd84-e78a-45d2-c5e0-012c6f76bd0c"
      },
      "source": [
        "X, target = batch\n",
        "print(X.shape)\n",
        "print(target)\n",
        "train_loader.dataset.target_class_idx_to_name"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([50, 1, 16000])\n",
            "tensor([ 6,  6,  0,  0,  0,  0,  0,  0, 10,  0,  6,  0,  1, 11,  0,  0,  0,  0,\n",
            "         0,  8,  7,  0,  0,  0,  0,  7,  0, 10,  0,  0,  9,  0,  0,  4,  4,  8,\n",
            "         4,  0,  3,  0,  0,  9,  5,  4,  0,  0,  0,  7,  7,  3])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'unknown',\n",
              " 1: 'silence',\n",
              " 2: 'yes',\n",
              " 3: 'no',\n",
              " 4: 'up',\n",
              " 5: 'down',\n",
              " 6: 'left',\n",
              " 7: 'right',\n",
              " 8: 'on',\n",
              " 9: 'off',\n",
              " 10: 'stop',\n",
              " 11: 'go'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5FtsCWQP2T7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b781df6f-4888-4acc-c4cc-ae7d66c5a271"
      },
      "source": [
        "train_loader.dataset.get_class_weights()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1356, 2.3723, 2.3723, 2.3812, 2.3941, 2.3954, 2.3994, 2.3825, 2.3672,\n",
              "        2.3994, 2.3408, 2.3710])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-tVvdboG4Vj"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from poutyne.framework import Model\n",
        "from torchsummary import summary\n",
        "cuda_device = 0\n",
        "device = torch.device(\"cuda:%d\" % cuda_device if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def train_and_test(mymodel, learning_rate = 0.001, mytrain_loader=train_loader, myvalid_loader=valid_loader, mytest_loader=test_loader):       \n",
        "    print(mymodel.to(device))\n",
        "    summary(mymodel, input_size=(1, 16000))\n",
        "\n",
        "    # Optimizer and loss function\n",
        "    #optimizer = optim.SGD(mymodel.parameters(), lr=learning_rate, weight_decay=0.001)\n",
        "    #optimizer = optim.Adam(mymodel.parameters(), lr=learning_rate)\n",
        "    optimizer = optim.Adam( filter(lambda p: p.requires_grad, mymodel.parameters()), lr=learning_rate )\n",
        "    #loss_function = nn.CrossEntropyLoss(weight=train_loader.dataset.get_class_weights())\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "    model = Model(mymodel, optimizer, loss_function, batch_metrics=['accuracy'], epoch_metrics=['f1'])\n",
        "\n",
        "    # Send model on GPU\n",
        "    model.to(device)\n",
        "\n",
        "    model.fit_generator(train_loader, valid_loader, epochs=10)\n",
        "\n",
        "\n",
        "    # Test\n",
        "    test_loss, test_acc = model.evaluate_generator(test_loader)\n",
        "    print('Test:\\n\\tLoss: {}\\n\\tAccuracy: {}'.format(test_loss, test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulS4YXFUwxCv"
      },
      "source": [
        "# LeNet Audio classification model\n",
        "\n",
        "Raw audio is converted into mel spectrogram and treated as a 2D image\n",
        "\n",
        "we use poutyne for training to reduce boilerplate code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc0JM6L9nGrC"
      },
      "source": [
        "## Task description\n",
        "\n",
        "1. Adapt the shape of the features to be classified using either x.view(?,?) or nn.Flatten() in the classifier definition\n",
        "\n",
        "2. Compute the correct values for the first linear layer of the classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WREbkaZkMi0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be2d2ac8-f9ab-4776-fc52-337873be0985"
      },
      "source": [
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self, num_classes=31):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.mels = nn.Sequential(\n",
        "            MelSpectrogram(),\n",
        "            nn.InstanceNorm2d(1) # Normalization\n",
        "        )\n",
        "\n",
        "        self.features = nn.Sequential( #bs, 1, 40, 101\n",
        "            nn.Conv2d(1, 20, kernel_size=5),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(20, 20, kernel_size=5),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(20* 7* 22, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        ## Compute mel filterbanks from raw audio\n",
        "        bs=x.shape[0]\n",
        "        debug=False\n",
        "        if debug:\n",
        "          print(x.shape) #bs, 1, 16000\n",
        "\n",
        "        x = self.mels(x)\n",
        "        if debug:\n",
        "          print(x.shape) #bs, 1, 40, 101\n",
        "        \n",
        "\n",
        "        ## Extract features\n",
        "        #bs, 20, ((40-5+1)/2 -5 +1)/2, int((int((40-5+1)/2) -5 +1)/2)\n",
        "        #bs, 20, 7, 22\n",
        "        x=self.features(x)\n",
        "        \n",
        "        if debug:\n",
        "          print(x.shape)\n",
        "        \n",
        "        ## Flatten features\n",
        "        #reshape -> pytorch view(bs, c*height*width)  \n",
        "        #bs, features\n",
        "        x = x.view(bs, -1)\n",
        "\n",
        "        ## Classify\n",
        "        x = self.classifier(x)\n",
        "\n",
        "        if debug:\n",
        "          raise Exception('In debug mode!')\n",
        "        return x\n",
        "\n",
        "mymodel = LeNet(num_classes = train_loader.dataset.get_n_classes())\n",
        "train_and_test(mymodel=mymodel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LeNet(\n",
            "  (mels): Sequential(\n",
            "    (0): MelSpectrogram(\n",
            "      (norm): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    )\n",
            "    (1): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): ReLU()\n",
            "    (3): Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): ReLU()\n",
            "    (6): Dropout2d(p=0.5, inplace=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=3080, out_features=256, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=256, out_features=12, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "    InstanceNorm2d-1           [-1, 1, 40, 101]               0\n",
            "            Conv2d-2           [-1, 20, 36, 97]             520\n",
            "         MaxPool2d-3           [-1, 20, 18, 48]               0\n",
            "              ReLU-4           [-1, 20, 18, 48]               0\n",
            "            Conv2d-5           [-1, 20, 14, 44]          10,020\n",
            "         MaxPool2d-6            [-1, 20, 7, 22]               0\n",
            "              ReLU-7            [-1, 20, 7, 22]               0\n",
            "         Dropout2d-8            [-1, 20, 7, 22]               0\n",
            "            Linear-9                  [-1, 256]         788,736\n",
            "             ReLU-10                  [-1, 256]               0\n",
            "           Linear-11                   [-1, 12]           3,084\n",
            "================================================================\n",
            "Total params: 802,360\n",
            "Trainable params: 802,360\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.06\n",
            "Forward/backward pass size (MB): 1.00\n",
            "Params size (MB): 3.06\n",
            "Estimated Total Size (MB): 4.12\n",
            "----------------------------------------------------------------\n",
            "Epoch:  1/10 Train steps: 1059 Val steps: 136 23.04s loss: 0.903007 acc: 72.947043 fscore_micro: 0.729470 val_loss: 0.439908 val_acc: 85.363342 val_fscore_micro: 0.853633\n",
            "Epoch:  2/10 Train steps: 1059 Val steps: 136 23.21s loss: 0.474376 acc: 84.864395 fscore_micro: 0.848644 val_loss: 0.326686 val_acc: 89.952927 val_fscore_micro: 0.899529\n",
            "Epoch:  3/10 Train steps: 1059 Val steps: 136 22.59s loss: 0.365664 acc: 88.088313 fscore_micro: 0.880883 val_loss: 0.282971 val_acc: 90.835540 val_fscore_micro: 0.908355\n",
            "Epoch:  4/10 Train steps: 1059 Val steps: 136 22.68s loss: 0.310153 acc: 89.961849 fscore_micro: 0.899619 val_loss: 0.266515 val_acc: 91.688732 val_fscore_micro: 0.916887\n",
            "Epoch:  5/10 Train steps: 1059 Val steps: 136 22.42s loss: 0.278397 acc: 90.847624 fscore_micro: 0.908476 val_loss: 0.255550 val_acc: 92.056487 val_fscore_micro: 0.920565\n",
            "Epoch:  6/10 Train steps: 1059 Val steps: 136 23.53s loss: 0.252381 acc: 91.852383 fscore_micro: 0.918524 val_loss: 0.237886 val_acc: 92.747867 val_fscore_micro: 0.927479\n",
            "Epoch:  7/10 Train steps: 1059 Val steps: 136 22.97s loss: 0.224283 acc: 92.707940 fscore_micro: 0.927079 val_loss: 0.235491 val_acc: 93.086202 val_fscore_micro: 0.930862\n",
            "Epoch:  8/10 Train steps: 1059 Val steps: 136 22.67s loss: 0.206966 acc: 93.217874 fscore_micro: 0.932179 val_loss: 0.219491 val_acc: 93.350986 val_fscore_micro: 0.933510\n",
            "Epoch:  9/10 Train steps: 1059 Val steps: 136 22.64s loss: 0.191708 acc: 93.652263 fscore_micro: 0.936523 val_loss: 0.221907 val_acc: 93.365696 val_fscore_micro: 0.933657\n",
            "Epoch: 10/10 Train steps: 1059 Val steps: 136 22.44s loss: 0.180764 acc: 94.065876 fscore_micro: 0.940659 val_loss: 0.238479 val_acc: 93.380406 val_fscore_micro: 0.933804\n",
            "Test steps: 137 2.36s test_loss: 0.238768 test_acc: 93.108998 test_fscore_micro: 0.931090     \n",
            "Test:\n",
            "\tLoss: 0.2387682497808898\n",
            "\tAccuracy: [93.1089978  0.93109  ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfus8c6SuRQn"
      },
      "source": [
        "## Check performance with data augmentation\n",
        "\n",
        "instead of training with train_loader we will train with train_loader_noise and evaluate on clean data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HW8RiwAt2zE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c42e5cde-ef3d-49ea-9ea3-4cdc5ede6e65"
      },
      "source": [
        "mymodel = LeNet(num_classes = train_loader.dataset.get_n_classes())\n",
        "train_and_test(mymodel=mymodel, mytrain_loader=train_loader_noise)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  1/10 Step: 1059/1059 100.00% |████████████████████|28.90s loss: 0.939477 acc: 71.868626 fscore_micro: 0.718686 val_loss: 0.475676 val_acc: 85.554575 val_fscore_micro: 0.855546\n",
            "Epoch:  2/10 Step: 1059/1059 100.00% |████████████████████|28.86s loss: 0.522849 acc: 83.317595 fscore_micro: 0.833176 val_loss: 0.356941 val_acc: 89.232127 val_fscore_micro: 0.892321\n",
            "Epoch:  3/10 Step: 1059/1059 100.00% |████████████████████|28.86s loss: 0.409748 acc: 86.941905 fscore_micro: 0.869419 val_loss: 0.315472 val_acc: 89.835246 val_fscore_micro: 0.898352\n",
            "Epoch:  4/10 Step: 1059/1059 100.00% |████████████████████|28.85s loss: 0.354356 acc: 88.545365 fscore_micro: 0.885454 val_loss: 0.291611 val_acc: 90.791409 val_fscore_micro: 0.907914\n",
            "Epoch:  5/10 Step: 1059/1059 100.00% |████████████████████|28.90s loss: 0.317648 acc: 89.884415 fscore_micro: 0.898844 val_loss: 0.256654 val_acc: 91.718152 val_fscore_micro: 0.917182\n",
            "Epoch:  6/10 Step: 1059/1059 100.00% |████████████████████|28.89s loss: 0.289189 acc: 90.649316 fscore_micro: 0.906493 val_loss: 0.247633 val_acc: 91.762283 val_fscore_micro: 0.917623\n",
            "Epoch:  7/10 Step: 1059/1059 100.00% |████████████████████|29.15s loss: 0.269252 acc: 91.299010 fscore_micro: 0.912990 val_loss: 0.243826 val_acc: 92.174169 val_fscore_micro: 0.921742\n",
            "Epoch:  8/10 Step: 1059/1059 100.00% |████████████████████|30.60s loss: 0.248994 acc: 91.771172 fscore_micro: 0.917712 val_loss: 0.231251 val_acc: 92.850838 val_fscore_micro: 0.928508\n",
            "Epoch:  9/10 Step: 1059/1059 100.00% |████████████████████|30.79s loss: 0.238321 acc: 92.130014 fscore_micro: 0.921300 val_loss: 0.234689 val_acc: 92.644896 val_fscore_micro: 0.926449\n",
            "Epoch: 10/10 Step: 1059/1059 100.00% |████████████████████|29.79s loss: 0.224171 acc: 92.711717 fscore_micro: 0.927117 val_loss: 0.238480 val_acc: 92.483083 val_fscore_micro: 0.924831\n",
            "Test:\n",
            "\tLoss: 0.24193006737698305\n",
            "\tAccuracy: [92.5969276  0.9259693]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqApa1RVuKh6"
      },
      "source": [
        "# VGG Audio classification model\n",
        "\n",
        "Let's borrow a successful image classification model and use it for audio mel-spectrograms \"images\" training the model from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDkfbFbweeZO"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py\n",
        "class VGG(nn.Module):\n",
        "\n",
        "    def __init__(self, vgg_name, num_classes=12):\n",
        "        super(VGG, self).__init__()\n",
        "        self.mels = nn.Sequential(\n",
        "            MelSpectrogram(),\n",
        "            nn.InstanceNorm2d(1) # Normalization\n",
        "          )\n",
        "        self.features = make_layers(cfg[vgg_name])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(1 * 3 * 512, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mels(x)\n",
        "        x = self.features(x)\n",
        "        \n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.weight.data.normal_(0, 0.01)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "\n",
        "def make_layers(cfg, batch_norm=True):\n",
        "    layers = []\n",
        "    in_channels = 1\n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "cfg = {\n",
        "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIB83n9CvJVw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "47b5bff2-31bd-4e2d-b1b7-2095adeaf5aa"
      },
      "source": [
        "vggmodel = VGG('VGG11',num_classes = train_loader.dataset.get_n_classes())\n",
        "train_and_test(mymodel=vggmodel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (mels): Sequential(\n",
            "    (0): MelSpectrogram(\n",
            "      (norm): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    )\n",
            "    (1): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU(inplace=True)\n",
            "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (24): ReLU(inplace=True)\n",
            "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=1536, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=12, bias=True)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "    InstanceNorm2d-1           [-1, 1, 40, 101]               0\n",
            "            Conv2d-2          [-1, 64, 40, 101]             640\n",
            "       BatchNorm2d-3          [-1, 64, 40, 101]             128\n",
            "              ReLU-4          [-1, 64, 40, 101]               0\n",
            "         MaxPool2d-5           [-1, 64, 20, 50]               0\n",
            "            Conv2d-6          [-1, 128, 20, 50]          73,856\n",
            "       BatchNorm2d-7          [-1, 128, 20, 50]             256\n",
            "              ReLU-8          [-1, 128, 20, 50]               0\n",
            "         MaxPool2d-9          [-1, 128, 10, 25]               0\n",
            "           Conv2d-10          [-1, 256, 10, 25]         295,168\n",
            "      BatchNorm2d-11          [-1, 256, 10, 25]             512\n",
            "             ReLU-12          [-1, 256, 10, 25]               0\n",
            "           Conv2d-13          [-1, 256, 10, 25]         590,080\n",
            "      BatchNorm2d-14          [-1, 256, 10, 25]             512\n",
            "             ReLU-15          [-1, 256, 10, 25]               0\n",
            "        MaxPool2d-16           [-1, 256, 5, 12]               0\n",
            "           Conv2d-17           [-1, 512, 5, 12]       1,180,160\n",
            "      BatchNorm2d-18           [-1, 512, 5, 12]           1,024\n",
            "             ReLU-19           [-1, 512, 5, 12]               0\n",
            "           Conv2d-20           [-1, 512, 5, 12]       2,359,808\n",
            "      BatchNorm2d-21           [-1, 512, 5, 12]           1,024\n",
            "             ReLU-22           [-1, 512, 5, 12]               0\n",
            "        MaxPool2d-23            [-1, 512, 2, 6]               0\n",
            "           Conv2d-24            [-1, 512, 2, 6]       2,359,808\n",
            "      BatchNorm2d-25            [-1, 512, 2, 6]           1,024\n",
            "             ReLU-26            [-1, 512, 2, 6]               0\n",
            "           Conv2d-27            [-1, 512, 2, 6]       2,359,808\n",
            "      BatchNorm2d-28            [-1, 512, 2, 6]           1,024\n",
            "             ReLU-29            [-1, 512, 2, 6]               0\n",
            "        MaxPool2d-30            [-1, 512, 1, 3]               0\n",
            "           Linear-31                 [-1, 4096]       6,295,552\n",
            "             ReLU-32                 [-1, 4096]               0\n",
            "          Dropout-33                 [-1, 4096]               0\n",
            "           Linear-34                 [-1, 4096]      16,781,312\n",
            "             ReLU-35                 [-1, 4096]               0\n",
            "          Dropout-36                 [-1, 4096]               0\n",
            "           Linear-37                   [-1, 12]          49,164\n",
            "================================================================\n",
            "Total params: 32,350,860\n",
            "Trainable params: 32,350,860\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.06\n",
            "Forward/backward pass size (MB): 14.59\n",
            "Params size (MB): 123.41\n",
            "Estimated Total Size (MB): 138.06\n",
            "----------------------------------------------------------------\n",
            "Epoch:  1/10 Step: 1059/1059 100.00% |████████████████████|71.93s loss: 1.011767 acc: 71.783637 fscore_micro: 0.717836 val_loss: 0.468992 val_acc: 85.054428 val_fscore_micro: 0.850544\n",
            "Epoch:  2/10 Step: 1059/1059 100.00% |████████████████████|71.71s loss: 0.323742 acc: 91.489764 fscore_micro: 0.914898 val_loss: 0.203234 val_acc: 94.145337 val_fscore_micro: 0.941453\n",
            "Epoch:  3/10 Step: 1059/1059 100.00% |████████████████████|71.70s loss: 0.214036 acc: 94.566367 fscore_micro: 0.945664 val_loss: 0.202335 val_acc: 94.277729 val_fscore_micro: 0.942777\n",
            "Epoch:  4/10 Step:  179/1059  16.90% |███▍                |ETA: 57.07s loss: 0.458702 acc: 90.000000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-44d5415f1bd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvggmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'VGG11'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_n_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_and_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmymodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvggmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-c64545d83eaa>\u001b[0m in \u001b[0;36mtrain_and_test\u001b[0;34m(mymodel, learning_rate, mytrain_loader, myvalid_loader, mytest_loader)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/poutyne/framework/model.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, train_generator, valid_generator, epochs, steps_per_epoch, validation_steps, batches_per_step, initial_epoch, verbose, progress_options, callbacks)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_generator_n_batches_per_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches_per_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_generator_one_batch_per_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/poutyne/framework/model.py\u001b[0m in \u001b[0;36m_fit_generator_one_batch_per_step\u001b[0;34m(self, epoch_iterator, callback_list)\u001b[0m\n\u001b[1;32m    615\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_training_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_step_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 617\u001b[0;31m                     \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m                     \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/poutyne/framework/model.py\u001b[0m in \u001b[0;36m_fit_batch\u001b[0;34m(self, x, y, callback, step, return_pred)\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLElEJnWdzFb"
      },
      "source": [
        "# TASK 2: Using models directly from torchvision.models\n",
        "\n",
        "Create an instance of VGG11 from torch.models and replace input 1st convolution with a 1-channel convolution and replace last output with Linear( dim, num_classes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RWPruVbeOpQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9bc0560a-882b-4928-a4c6-9b8565912ef1"
      },
      "source": [
        "origVGG = models.vgg11(pretrained=False)\n",
        "print(origVGG)\n",
        "print(origVGG.classifier[6]) #last linear layer \n",
        "print(origVGG.features[0]) #first input convolutions\n",
        "num_classes = train_loader.dataset.get_n_classes()\n",
        "origVGG.features[0] = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "origVGG.classifier[6] = nn.Linear(in_features=4096, out_features=num_classes, bias=True)\n",
        "\n",
        "\n",
        "MyModel = nn.Sequential(\n",
        "            MelSpectrogram(),\n",
        "            nn.InstanceNorm2d(1), # Normalization\n",
        "            origVGG,\n",
        "          )\n",
        "train_and_test(mymodel=MyModel)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): ReLU(inplace=True)\n",
            "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU(inplace=True)\n",
            "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n",
            "Linear(in_features=4096, out_features=1000, bias=True)\n",
            "Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "Sequential(\n",
            "  (0): MelSpectrogram(\n",
            "    (norm): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (1): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (2): VGG(\n",
            "    (features): Sequential(\n",
            "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): ReLU(inplace=True)\n",
            "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (7): ReLU(inplace=True)\n",
            "      (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (9): ReLU(inplace=True)\n",
            "      (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (12): ReLU(inplace=True)\n",
            "      (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (14): ReLU(inplace=True)\n",
            "      (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (17): ReLU(inplace=True)\n",
            "      (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (19): ReLU(inplace=True)\n",
            "      (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "    (classifier): Sequential(\n",
            "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "      (4): ReLU(inplace=True)\n",
            "      (5): Dropout(p=0.5, inplace=False)\n",
            "      (6): Linear(in_features=4096, out_features=12, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "    InstanceNorm2d-1           [-1, 1, 40, 101]               0\n",
            "            Conv2d-2          [-1, 64, 40, 101]             640\n",
            "              ReLU-3          [-1, 64, 40, 101]               0\n",
            "         MaxPool2d-4           [-1, 64, 20, 50]               0\n",
            "            Conv2d-5          [-1, 128, 20, 50]          73,856\n",
            "              ReLU-6          [-1, 128, 20, 50]               0\n",
            "         MaxPool2d-7          [-1, 128, 10, 25]               0\n",
            "            Conv2d-8          [-1, 256, 10, 25]         295,168\n",
            "              ReLU-9          [-1, 256, 10, 25]               0\n",
            "           Conv2d-10          [-1, 256, 10, 25]         590,080\n",
            "             ReLU-11          [-1, 256, 10, 25]               0\n",
            "        MaxPool2d-12           [-1, 256, 5, 12]               0\n",
            "           Conv2d-13           [-1, 512, 5, 12]       1,180,160\n",
            "             ReLU-14           [-1, 512, 5, 12]               0\n",
            "           Conv2d-15           [-1, 512, 5, 12]       2,359,808\n",
            "             ReLU-16           [-1, 512, 5, 12]               0\n",
            "        MaxPool2d-17            [-1, 512, 2, 6]               0\n",
            "           Conv2d-18            [-1, 512, 2, 6]       2,359,808\n",
            "             ReLU-19            [-1, 512, 2, 6]               0\n",
            "           Conv2d-20            [-1, 512, 2, 6]       2,359,808\n",
            "             ReLU-21            [-1, 512, 2, 6]               0\n",
            "        MaxPool2d-22            [-1, 512, 1, 3]               0\n",
            "AdaptiveAvgPool2d-23            [-1, 512, 7, 7]               0\n",
            "           Linear-24                 [-1, 4096]     102,764,544\n",
            "             ReLU-25                 [-1, 4096]               0\n",
            "          Dropout-26                 [-1, 4096]               0\n",
            "           Linear-27                 [-1, 4096]      16,781,312\n",
            "             ReLU-28                 [-1, 4096]               0\n",
            "          Dropout-29                 [-1, 4096]               0\n",
            "           Linear-30                   [-1, 12]          49,164\n",
            "              VGG-31                   [-1, 12]               0\n",
            "================================================================\n",
            "Total params: 128,814,348\n",
            "Trainable params: 128,814,348\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.06\n",
            "Forward/backward pass size (MB): 10.29\n",
            "Params size (MB): 491.39\n",
            "Estimated Total Size (MB): 501.74\n",
            "----------------------------------------------------------------\n",
            "Epoch:  1/10 Step:  536/1059  50.61% |██████████          |ETA: 56.25s loss: 0.353986 acc: 88.000000"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-0ccfb07a9c07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0morigVGG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m           )\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain_and_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmymodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMyModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-c64545d83eaa>\u001b[0m in \u001b[0;36mtrain_and_test\u001b[0;34m(mymodel, learning_rate, mytrain_loader, myvalid_loader, mytest_loader)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/poutyne/framework/model.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, train_generator, valid_generator, epochs, steps_per_epoch, validation_steps, batches_per_step, initial_epoch, verbose, progress_options, callbacks)\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_generator_n_batches_per_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches_per_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_generator_one_batch_per_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/poutyne/framework/model.py\u001b[0m in \u001b[0;36m_fit_generator_one_batch_per_step\u001b[0;34m(self, epoch_iterator, callback_list)\u001b[0m\n\u001b[1;32m    626\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_training_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_step_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m                     \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m                     \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/poutyne/framework/model.py\u001b[0m in \u001b[0;36m_fit_batch\u001b[0;34m(self, x, y, callback, step, return_pred)\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4t6Kw-WgcWS"
      },
      "source": [
        "# Task 3\n",
        "\n",
        "Try to train a Resnet-18\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NCfZKUZzgoBq",
        "outputId": "e1fcdd3c-e0bc-44a1-ccb1-da8567fdab0f"
      },
      "source": [
        "\n",
        "#take a look at https://pytorch.org/vision/0.8/_modules/torchvision/models/resnet.html#resnet18\n",
        "resnet18 = models.resnet18(pretrained=False)\n",
        "print(resnet18)\n",
        "#adapt resnet18 input and output\n",
        "num_classes = train_loader.dataset.get_n_classes()\n",
        "resnet18.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "resnet18.fc = \n",
        "MyResnet = nn.Sequential(\n",
        "            MelSpectrogram(),\n",
        "            nn.InstanceNorm2d(1), # Normalization\n",
        "            resnet18,\n",
        "          )\n",
        "train_and_test(mymodel=MyResnet)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            ")\n",
            "Sequential(\n",
            "  (0): MelSpectrogram(\n",
            "    (norm): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            "  (1): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (2): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-c7df0226aaa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mresnet18\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m           )\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtrain_and_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmymodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMyResnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-c64545d83eaa>\u001b[0m in \u001b[0;36mtrain_and_test\u001b[0;34m(mymodel, learning_rate, mytrain_loader, myvalid_loader, mytest_loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_and_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmymodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmytrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmyvalid_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmytest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmymodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmymodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Optimizer and loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 420\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 7, 7], expected input[2, 1, 40, 101] to have 3 channels, but got 1 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xCi5wSduszZ"
      },
      "source": [
        "## VGG fine tuning\n",
        "\n",
        "Use a pretrained VGG, freezing its parameters and replacing the last linear layer with a new one with the needed num_classes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEsZgiTzgTsO"
      },
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MyVGG(nn.Module):\n",
        "    def __init__(self, num_classes=12):\n",
        "          super(MyVGG, self).__init__()\n",
        "          self.origVGG = models.vgg11(pretrained=True)\n",
        "          for param in self.origVGG.parameters():\n",
        "              param.requires_grad = False\n",
        "\n",
        "          in_features = self.origVGG.classifier[6].in_features\n",
        "          self.origVGG.classifier[6] = nn.Linear(in_features, num_classes)\n",
        "          conv1 = nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "          self.origVGG.features[0] = conv1\n",
        "          self.mels = nn.Sequential(\n",
        "            MelSpectrogram(),\n",
        "            nn.InstanceNorm2d(1) # Normalization\n",
        "          )\n",
        "          \n",
        "    def forward(self, x):\n",
        "        x = self.mels(x)\n",
        "        x = self.origVGG(x)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBZy5VE1jDvT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0e02de92-7f93-4673-f5db-a7dd65df0a25"
      },
      "source": [
        "mymodel = MyVGG(num_classes = train_loader.dataset.get_n_classes())\n",
        "train_and_test(mymodel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MyVGG(\n",
            "  (origVGG): VGG(\n",
            "    (features): Sequential(\n",
            "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): ReLU(inplace=True)\n",
            "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (7): ReLU(inplace=True)\n",
            "      (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (9): ReLU(inplace=True)\n",
            "      (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (12): ReLU(inplace=True)\n",
            "      (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (14): ReLU(inplace=True)\n",
            "      (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (17): ReLU(inplace=True)\n",
            "      (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (19): ReLU(inplace=True)\n",
            "      (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "    (classifier): Sequential(\n",
            "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "      (4): ReLU(inplace=True)\n",
            "      (5): Dropout(p=0.5, inplace=False)\n",
            "      (6): Linear(in_features=4096, out_features=12, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (mels): Sequential(\n",
            "    (0): MelSpectrogram(\n",
            "      (norm): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    )\n",
            "    (1): InstanceNorm2d(1, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  )\n",
            ")\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "    InstanceNorm2d-1           [-1, 1, 40, 101]               0\n",
            "            Conv2d-2          [-1, 64, 40, 101]             640\n",
            "              ReLU-3          [-1, 64, 40, 101]               0\n",
            "         MaxPool2d-4           [-1, 64, 20, 50]               0\n",
            "            Conv2d-5          [-1, 128, 20, 50]          73,856\n",
            "              ReLU-6          [-1, 128, 20, 50]               0\n",
            "         MaxPool2d-7          [-1, 128, 10, 25]               0\n",
            "            Conv2d-8          [-1, 256, 10, 25]         295,168\n",
            "              ReLU-9          [-1, 256, 10, 25]               0\n",
            "           Conv2d-10          [-1, 256, 10, 25]         590,080\n",
            "             ReLU-11          [-1, 256, 10, 25]               0\n",
            "        MaxPool2d-12           [-1, 256, 5, 12]               0\n",
            "           Conv2d-13           [-1, 512, 5, 12]       1,180,160\n",
            "             ReLU-14           [-1, 512, 5, 12]               0\n",
            "           Conv2d-15           [-1, 512, 5, 12]       2,359,808\n",
            "             ReLU-16           [-1, 512, 5, 12]               0\n",
            "        MaxPool2d-17            [-1, 512, 2, 6]               0\n",
            "           Conv2d-18            [-1, 512, 2, 6]       2,359,808\n",
            "             ReLU-19            [-1, 512, 2, 6]               0\n",
            "           Conv2d-20            [-1, 512, 2, 6]       2,359,808\n",
            "             ReLU-21            [-1, 512, 2, 6]               0\n",
            "        MaxPool2d-22            [-1, 512, 1, 3]               0\n",
            "AdaptiveAvgPool2d-23            [-1, 512, 7, 7]               0\n",
            "           Linear-24                 [-1, 4096]     102,764,544\n",
            "             ReLU-25                 [-1, 4096]               0\n",
            "          Dropout-26                 [-1, 4096]               0\n",
            "           Linear-27                 [-1, 4096]      16,781,312\n",
            "             ReLU-28                 [-1, 4096]               0\n",
            "          Dropout-29                 [-1, 4096]               0\n",
            "           Linear-30                   [-1, 12]          49,164\n",
            "              VGG-31                   [-1, 12]               0\n",
            "================================================================\n",
            "Total params: 128,814,348\n",
            "Trainable params: 49,804\n",
            "Non-trainable params: 128,764,544\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.06\n",
            "Forward/backward pass size (MB): 10.29\n",
            "Params size (MB): 491.39\n",
            "Estimated Total Size (MB): 501.74\n",
            "----------------------------------------------------------------\n",
            "Epoch 1/10 52.88s Step 1059/1059: loss: 1.155943, acc: 66.253683, fscore_micro: 0.662537, val_loss: 0.974924, val_acc: 69.035010, val_fscore_micro: 0.690350\n",
            "Epoch 2/10 52.38s Step 1059/1059: loss: 0.990954, acc: 69.326509, fscore_micro: 0.693265, val_loss: 0.913683, val_acc: 71.977052, val_fscore_micro: 0.719770\n",
            "Epoch 3/10 52.37s Step 1059/1059: loss: 0.936132, acc: 70.875198, fscore_micro: 0.708752, val_loss: 0.839494, val_acc: 74.110033, val_fscore_micro: 0.741100\n",
            "Epoch 4/10 52.21s Step 1059/1059: loss: 0.900602, acc: 71.689205, fscore_micro: 0.716892, val_loss: 0.799373, val_acc: 75.213298, val_fscore_micro: 0.752133\n",
            "Epoch 5/10 51.97s Step 1059/1059: loss: 0.870829, acc: 72.523986, fscore_micro: 0.725240, val_loss: 0.765755, val_acc: 76.228303, val_fscore_micro: 0.762283\n",
            "Epoch 6/10 51.71s Step 1059/1059: loss: 0.850711, acc: 72.984815, fscore_micro: 0.729848, val_loss: 0.755625, val_acc: 76.743160, val_fscore_micro: 0.767432\n",
            "Epoch 7/10 51.84s Step 1059/1059: loss: 0.833301, acc: 73.385208, fscore_micro: 0.733852, val_loss: 0.728989, val_acc: 76.493086, val_fscore_micro: 0.764931\n",
            "Epoch 8/10 51.83s Step 1059/1059: loss: 0.805590, acc: 74.471179, fscore_micro: 0.744712, val_loss: 0.743267, val_acc: 75.316270, val_fscore_micro: 0.753163\n",
            "Epoch 9/10 51.85s Step 1059/1059: loss: 0.802726, acc: 74.525950, fscore_micro: 0.745260, val_loss: 0.749996, val_acc: 76.272433, val_fscore_micro: 0.762724\n",
            "Epoch 10/10 51.68s Step 1059/1059: loss: 0.790071, acc: 74.839465, fscore_micro: 0.748395, val_loss: 0.679912, val_acc: 77.861136, val_fscore_micro: 0.778611\n",
            "Test:\n",
            "\tLoss: 0.6900103190244771\n",
            "\tAccuracy: [77.79078293  0.77790785]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywxJY9LpvGGC"
      },
      "source": [
        "# TDNN Classification model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLvuuj0KwWab"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class TDNN(nn.Module):\n",
        "    def __init__(self, num_classes=12):\n",
        "        super(TDNN, self).__init__()\n",
        "        self.tdnn = nn.Sequential(\n",
        "            nn.Conv1d(40, 450, stride=1, dilation=1, kernel_size=3),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv1d(450, 450, stride=1, dilation=1, kernel_size=4),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv1d(450, 450, stride=1, dilation=3, kernel_size=3),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv1d(450, 450, stride=1, dilation=3, kernel_size=3),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv1d(450, 450, stride=1, dilation=3, kernel_size=3),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv1d(450, 450, stride=1, dilation=3, kernel_size=3),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv1d(450, 450, stride=1, dilation=3, kernel_size=3),\n",
        "            nn.ReLU(True),\n",
        "            nn.MaxPool1d(3, stride=3),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(9000, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "        self.mels = nn.Sequential(\n",
        "            MelSpectrogram(),\n",
        "            nn.InstanceNorm2d(1) # Normalization\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x=self.mels(x)\n",
        "        x.squeeze_(1)\n",
        "        x = self.tdnn(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}