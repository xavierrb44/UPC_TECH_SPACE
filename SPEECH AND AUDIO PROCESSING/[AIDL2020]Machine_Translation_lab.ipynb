{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "[AIDL2020]Machine_Translation_lab.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8EvKKcc-mL0"
      },
      "source": [
        "#Introduction\n",
        "\n",
        "This lab is devoted to **Neural Machine Translation.**\n",
        "\n",
        "Today we will train and evaluate RNN Encoder-Decoder with Attention."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOW30qYBBK_w"
      },
      "source": [
        "# RNN Encoder-Decoder with Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t8P-WMyBj8z"
      },
      "source": [
        "## Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f61dHoYyBeTh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "359581a1-2367-427f-d7c8-b724c4571b4d"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import math, copy, time\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE=torch.device('cuda:0')\n",
        "print(\"CUDA is available:\", USE_CUDA)\n",
        "print(\"Which device:\", DEVICE)\n",
        "\n",
        "seed = 1234\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available: True\n",
            "Which device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_i9DppY_ZqUJ"
      },
      "source": [
        "We will use [spacy](https://github.com/explosion/spaCy) for tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZaRIuIjvhay"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK7aglukvNos",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "c8cc2fac-c453-450e-e420-05fd9dee89b0"
      },
      "source": [
        "pip install torchtext==0.4.0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n",
            "\r\u001b[K     |██████▏                         | 10kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 20kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 30kB 6.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 40kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 51kB 5.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (1.18.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (1.5.1+cu101)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (1.12.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (2020.4.5.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (1.24.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.4.0) (0.16.0)\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.8.0a0+a664981\n",
            "    Uninstalling torchtext-0.8.0a0+a664981:\n",
            "      Successfully uninstalled torchtext-0.8.0a0+a664981\n",
            "Successfully installed torchtext-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snmDQ9DWFO_u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ef6608fb-2811-4629-dc9e-c00e86b9bdad"
      },
      "source": [
        "!pip3 install git+git://github.com/pytorch/text spacy \n",
        "!python -m spacy download en\n",
        "!python -m spacy download de"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/pytorch/text\n",
            "  Cloning git://github.com/pytorch/text to /tmp/pip-req-build-07_vqi6z\n",
            "  Running command git clone -q git://github.com/pytorch/text /tmp/pip-req-build-07_vqi6z\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Requirement already satisfied (use --upgrade to upgrade): torchtext==0.8.0a0+a664981 from git+git://github.com/pytorch/text in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.8.0a0+a664981) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.8.0a0+a664981) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.8.0a0+a664981) (1.5.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.8.0a0+a664981) (1.18.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from torchtext==0.8.0a0+a664981) (0.1.91)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (47.3.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.8.0a0+a664981) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.8.0a0+a664981) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.8.0a0+a664981) (2020.4.5.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.8.0a0+a664981) (1.24.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.8.0a0+a664981) (0.16.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n",
            "Building wheels for collected packages: torchtext\n",
            "  Building wheel for torchtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchtext: filename=torchtext-0.8.0a0+a664981-cp36-cp36m-linux_x86_64.whl size=3708007 sha256=5bcfb80616e52b407ba546ed457b959984318b1aea4397a9c33a246140ef7e0a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3ybxj3sj/wheels/39/42/ff/82f5ccbb0f30b25e14610376f5d0c67913fc05017dab59f8eb\n",
            "Successfully built torchtext\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (47.3.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Requirement already satisfied: de_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz#egg=de_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (47.3.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.6.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.4.5.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwmChUernDpd"
      },
      "source": [
        "## Data\n",
        "Machine Translation dataset is a parallel (bilingual) corpus. Which means it is a dataset created out of source language sentences with their corresponding target language translations. We need to take care of two things:\n",
        "* source language vocabulary and target language vocabulary\n",
        "* source sentences and their translations (target sentences) may have different lenghts => variable-length sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miEwqs_Ve0xd"
      },
      "source": [
        "###Exercise 1: Preprocessing\n",
        "\n",
        "We will download, lowercase and tokenize the IWSLT data for the English-German language pair.\n",
        "\n",
        "As we want our model to perform fast, we only include words that occur min 5 times as well as limit the length of sentences to max 25 words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-YoawDlgF5j"
      },
      "source": [
        "import spacy\n",
        "from torchtext import data, datasets\n",
        "\n",
        "SOS_TOKEN = \"<s>\"\n",
        "EOS_TOKEN = \"</s>\"\n",
        "UNK_TOKEN = \"<unk>\"\n",
        "PAD_TOKEN = \"<pad>\"\n",
        "MIN_FREQ = 5  # min number of times a word occurs\n",
        "MAX_LEN = 25  # max number of words per sentence\n",
        "\n",
        "spacy_de = spacy.load('de')\n",
        "spacy_en = spacy.load('en')\n",
        "\n",
        "def tokenize_de(text):\n",
        "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "SRC = data.Field(tokenize=tokenize_de, batch_first=True, lower=True, include_lengths=True,\n",
        "                  unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=None, eos_token=EOS_TOKEN)\n",
        "TRG = data.Field(tokenize=tokenize_en, batch_first=True, lower=True, include_lengths=True,\n",
        "                  unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=SOS_TOKEN, eos_token=EOS_TOKEN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbyRWNoUfkSN"
      },
      "source": [
        "####Exercise 1.1: Split data to training, validation and test datasets\n",
        "\n",
        "Use `datasets.IWSLT.splits` [method](https://torchtext.readthedocs.io/en/latest/data.html#torchtext.data.Dataset.splits). \n",
        "\n",
        "Execution of this cell will take a while."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H3yar0SFfTM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "4efaf058-f49d-4bab-a6d7-5d63e78a5257"
      },
      "source": [
        "train_data, valid_data, test_data = datasets.IWSLT.splits(\n",
        "    exts=('.de', '.en'), fields=(SRC, TRG), \n",
        "    filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and len(vars(x)['trg']) <= MAX_LEN)#TODO"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading de-en.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "de-en.tgz: 100%|██████████| 24.2M/24.2M [00:01<00:00, 18.2MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".data/iwslt/de-en/IWSLT16.TED.tst2013.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2014.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2011.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2010.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.dev2012.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.dev2012.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2014.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2013.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2014.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2014.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.dev2010.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.dev2010.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2013.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2012.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2012.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2013.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2010.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2011.de-en.de.xml\n",
            ".data/iwslt/de-en/train.tags.de-en.de\n",
            ".data/iwslt/de-en/train.tags.de-en.en\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JoDj1tBfl9w"
      },
      "source": [
        "####Exercise 1.2: Build vocabulary for SRC and TRG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXootz3mevNM"
      },
      "source": [
        "SRC.build_vocab(train_data.src, min_freq=MIN_FREQ)#TODO\n",
        "TRG.build_vocab(train_data.trg, min_freq=MIN_FREQ)#TODO\n",
        "\n",
        "PAD_INDEX = TRG.vocab.stoi[PAD_TOKEN]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tETI5F57fZA5"
      },
      "source": [
        "Now, let's check how our data look"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFxdKI_WGimC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "249d0281-5c31-4956-f0be-3cbba01025fa"
      },
      "source": [
        "def show_data_stats(train_data, valid_data, test_data, src_field, trg_field):\n",
        "    print(\"src vocabulary size:\", len(src_field.vocab))\n",
        "    print(\"trg vocabulary size:\", len(trg_field.vocab), \"\\n\")\n",
        "\n",
        "    print(\"Number of sentence pairs:\")\n",
        "    print('train:', len(train_data))\n",
        "    print('valid:', len(valid_data))\n",
        "    print('test:', len(test_data), \"\\n\")\n",
        "\n",
        "    print(\"Let's take a look at an exemplary pair of sentences:\")\n",
        "    print(\"src:\", \" \".join(vars(train_data[20])['src']))\n",
        "    print(\"trg:\", \" \".join(vars(train_data[20])['trg']), \"\\n\")   \n",
        "    \n",
        "show_data_stats(train_data, valid_data, test_data, SRC, TRG)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src vocabulary size: 15765\n",
            "trg vocabulary size: 13002 \n",
            "\n",
            "Number of sentence pairs:\n",
            "train: 143115\n",
            "valid: 690\n",
            "test: 963 \n",
            "\n",
            "Let's take a look at an exemplary pair of sentences:\n",
            "src: es ist eine kolonie von tieren .\n",
            "trg: it 's a colonial animal . \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBPa1Rn3BvIc"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdIgMQLcqge1"
      },
      "source": [
        "Below we implement a standard Encoder-Decoder architecture. The encoder returns its final states (`encoder_final`), which is used to initialize the decoder RNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUKvg_GRB0L7"
      },
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_embed, trg_embed, generator):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.trg_embed = trg_embed\n",
        "        self.generator = generator\n",
        "        \n",
        "    def forward(self, src, trg, src_mask, trg_mask, src_lengths, trg_lengths):\n",
        "        encoder_hidden, encoder_final = self.encode(src, src_mask, src_lengths)\n",
        "        return self.decode(encoder_hidden, encoder_final, src_mask, trg, trg_mask)\n",
        "    \n",
        "    def encode(self, src, src_mask, src_lengths):\n",
        "        return self.encoder(self.src_embed(src), src_mask, src_lengths)\n",
        "    \n",
        "    def decode(self, encoder_hidden, encoder_final, src_mask, trg, trg_mask,\n",
        "               decoder_hidden=None):\n",
        "        return self.decoder(self.trg_embed(trg), encoder_hidden, encoder_final,\n",
        "                            src_mask, trg_mask, hidden=decoder_hidden)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWHWIVwjrSAZ"
      },
      "source": [
        "####Exercise 2.1: Define softmax generation step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1OwLjdkB_j4"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, hidden_size, vocab_size):\n",
        "        super(Generator, self).__init__()\n",
        "        self.proj = nn.Linear(hidden_size, vocab_size, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.log_softmax(self.proj(x), dim=-1)#TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4cBuMeoCLyE"
      },
      "source": [
        "### Encoder\n",
        "\n",
        "We will implement a bi-directional GRU encoder.\n",
        "We will leverage mini-batches to speed up computations. Remember that sentences in mini-batches may be of different lenghts. PyTorch is able to deal with this by means of `pack_padded_sequence` and `pad_packed_sequence` functions, which support masking and padding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S40wCHxvtONT"
      },
      "source": [
        "####Exercise 2.2: Return a final vector of the source sentence\n",
        "\n",
        "Encoder reads a source sentence and generates hidden states. Once finished, the encoder returns a final vector, which represents the complete sentence. **It is constructed as a concatenation of the last and the first hidden states (because it is bi-directional!)**. This final vector will be used to initialize the decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRl-utHcCN_t"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.GRU(input_size, hidden_size, num_layers, \n",
        "                          batch_first=True, bidirectional=True, dropout=dropout)\n",
        "        \n",
        "    def forward(self, x, mask, lengths):\n",
        "        packed = pack_padded_sequence(x, lengths, batch_first=True)\n",
        "        output, final = self.rnn(packed)\n",
        "        output, _ = pad_packed_sequence(output, batch_first=True)\n",
        "\n",
        "        left_right_final = final[0:final.size(0):2]\n",
        "        right_left_final = final[1:final.size(0):2]\n",
        "        final = torch.cat([left_right_final, right_left_final], dim=2)#TODO\n",
        "\n",
        "        return output, final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JzJpm74CWI2"
      },
      "source": [
        "### Decoder\n",
        "\n",
        "Initial hidden state of the decoder is initialized with a projection of the encoder final state.\n",
        "In function `forward` there's a for-loop that computes the decoder hidden states one time step at a time. In training mode we use `teacher forcing` as we know the targets. In prediction time the model uses embedding of the previously predicted word and the last hidden state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB0K-P24wHOB"
      },
      "source": [
        "####Exercise 2.3: Initialize decoder conditioned on the encoder final vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry_6OqkdCX8F"
      },
      "source": [
        "class Decoder(nn.Module):    \n",
        "    def __init__(self, emb_size, hidden_size, attention, num_layers=1, dropout=0.5, bridge=True):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.attention = attention\n",
        "        self.dropout = dropout\n",
        "                 \n",
        "        self.rnn = nn.GRU(emb_size + 2*hidden_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "                 \n",
        "        # Initialization from the final encoder state\n",
        "        self.bridge = nn.Linear(2*hidden_size, hidden_size, bias=True) if bridge else None\n",
        "        self.dropout_layer = nn.Dropout(p=dropout)\n",
        "        self.pre_output_layer = nn.Linear(hidden_size + 2*hidden_size + emb_size, hidden_size, bias=False)\n",
        "        \n",
        "    def forward_step(self, prev_embed, encoder_hidden, src_mask, proj_key, hidden):\n",
        "        query = hidden[-1].unsqueeze(1)\n",
        "        context, attn_probs = self.attention(\n",
        "            query=query, proj_key=proj_key,\n",
        "            value=encoder_hidden, mask=src_mask)\n",
        "        \n",
        "        rnn_input = torch.cat([prev_embed, context], dim=2)\n",
        "        output, hidden = self.rnn(rnn_input, hidden)\n",
        "        \n",
        "        pre_output = torch.cat([prev_embed, output, context], dim=2)\n",
        "        pre_output = self.dropout_layer(pre_output)\n",
        "        pre_output = self.pre_output_layer(pre_output)\n",
        "\n",
        "        return output, hidden, pre_output\n",
        "    \n",
        "    def forward(self, trg_embed, encoder_hidden, encoder_final, \n",
        "                src_mask, trg_mask, hidden=None, max_len=None):\n",
        "        if max_len is None:\n",
        "            max_len = trg_mask.size(-1)\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(encoder_final)\n",
        "\n",
        "        proj_key = self.attention.key_layer(encoder_hidden)\n",
        "        decoder_states = []\n",
        "        pre_output_vectors = []\n",
        "        \n",
        "        for i in range(max_len):\n",
        "            prev_embed = trg_embed[:, i].unsqueeze(1)\n",
        "            output, hidden, pre_output = self.forward_step(\n",
        "              prev_embed, encoder_hidden, src_mask, proj_key, hidden)\n",
        "            decoder_states.append(output)\n",
        "            pre_output_vectors.append(pre_output)\n",
        "\n",
        "        decoder_states = torch.cat(decoder_states, dim=1)\n",
        "        pre_output_vectors = torch.cat(pre_output_vectors, dim=1)\n",
        "        return decoder_states, hidden, pre_output_vectors\n",
        "\n",
        "    def init_hidden(self, encoder_final):\n",
        "        if encoder_final is None:\n",
        "            return None\n",
        "        return torch.tanh(self.bridge(encoder_final))#TODO            \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUHKfKxUCiG9"
      },
      "source": [
        "### Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx-B7ha32tkt"
      },
      "source": [
        "####Exercise 2.4: Compute context vector, which is the weighted sum of the encoder hidden states (values)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxKvpgzQCj_l"
      },
      "source": [
        "class AdditiveAttention(nn.Module):    \n",
        "    def __init__(self, hidden_size, key_size=None, query_size=None):\n",
        "        super(AdditiveAttention, self).__init__()\n",
        "        \n",
        "        # We assume a bi-directional encoder so key_size is 2*hidden_size\n",
        "        key_size = 2 * hidden_size if key_size is None else key_size\n",
        "        query_size = hidden_size if query_size is None else query_size\n",
        "\n",
        "        self.key_layer = nn.Linear(key_size, hidden_size, bias=False)\n",
        "        self.query_layer = nn.Linear(query_size, hidden_size, bias=False)\n",
        "        self.energy_layer = nn.Linear(hidden_size, 1, bias=False)\n",
        "\n",
        "        self.alphas = None\n",
        "        \n",
        "    def forward(self, query=None, proj_key=None, value=None, mask=None):\n",
        "        assert mask is not None, \"mask is required\"\n",
        "        query = self.query_layer(query)\n",
        "\n",
        "        scores = self.energy_layer(torch.tanh(query + proj_key))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "        scores.data.masked_fill_(mask == 0, -float('inf'))\n",
        "        \n",
        "        alphas = F.softmax(scores, dim=-1)\n",
        "        self.alphas = alphas               \n",
        "        context = torch.bmm(alphas, value)#TODO\n",
        "        \n",
        "        return context, alphas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir5DfTnzC0Wp"
      },
      "source": [
        "### Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtWc2AibCy5y"
      },
      "source": [
        "def init_model(src_vocab, tgt_vocab, emb_size=256, hidden_size=512, num_layers=1, dropout=0.1):\n",
        "    attention = AdditiveAttention(hidden_size)\n",
        "    model = EncoderDecoder(\n",
        "        Encoder(emb_size, hidden_size, num_layers=num_layers, dropout=dropout),\n",
        "        Decoder(emb_size, hidden_size, attention, num_layers=num_layers, dropout=dropout),\n",
        "        nn.Embedding(src_vocab, emb_size),\n",
        "        nn.Embedding(tgt_vocab, emb_size),\n",
        "        Generator(hidden_size, tgt_vocab))\n",
        "\n",
        "    return model.cuda() if USE_CUDA else model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayiCm0DPC7PD"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQujYfEgDCfo"
      },
      "source": [
        "### Batching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxlIR-0eC9DJ"
      },
      "source": [
        "class Batch:\n",
        "    def __init__(self, src, trg, pad_index=0):\n",
        "        \n",
        "        src, src_lengths = src\n",
        "        \n",
        "        self.src = src\n",
        "        self.src_lengths = src_lengths\n",
        "        self.src_mask = (src != pad_index).unsqueeze(-2)\n",
        "        self.nseqs = src.size(0)\n",
        "        \n",
        "        self.trg = None\n",
        "        self.trg_y = None\n",
        "        self.trg_mask = None\n",
        "        self.trg_lengths = None\n",
        "        self.ntokens = None\n",
        "\n",
        "        if trg is not None:\n",
        "            trg, trg_lengths = trg\n",
        "            self.trg = trg[:, :-1]\n",
        "            self.trg_lengths = trg_lengths\n",
        "            self.trg_y = trg[:, 1:]\n",
        "            self.trg_mask = (self.trg_y != pad_index)\n",
        "            self.ntokens = (self.trg_y != pad_index).data.sum().item()\n",
        "        \n",
        "        if USE_CUDA:\n",
        "            self.src = self.src.cuda()\n",
        "            self.src_mask = self.src_mask.cuda()\n",
        "\n",
        "            if trg is not None:\n",
        "                self.trg = self.trg.cuda()\n",
        "                self.trg_y = self.trg_y.cuda()\n",
        "                self.trg_mask = self.trg_mask.cuda()\n",
        "                "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxHU2SizGzUG"
      },
      "source": [
        "train_iter = data.BucketIterator(train_data, batch_size=64, train=True, \n",
        "                                 sort_within_batch=True, \n",
        "                                 sort_key=lambda x: (len(x.src), len(x.trg)), repeat=False,\n",
        "                                 device=DEVICE)\n",
        "valid_iter = data.Iterator(valid_data, batch_size=1, train=False, sort=False, repeat=False, \n",
        "                           device=DEVICE)\n",
        "\n",
        "\n",
        "def rebatch(pad_idx, batch):\n",
        "    return Batch(batch.src, batch.trg, pad_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULUqc-DsDIHk"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoNtRJSiDPiZ"
      },
      "source": [
        "def run_epoch(data_iter, model, loss_compute, print_every=50):\n",
        "    start = time.time()\n",
        "    total_tokens = 0\n",
        "    total_loss = 0\n",
        "    print_tokens = 0\n",
        "\n",
        "    for i, batch in enumerate(data_iter, 1):\n",
        "        \n",
        "        out, _, pre_output = model.forward(batch.src, batch.trg,\n",
        "                                           batch.src_mask, batch.trg_mask,\n",
        "                                           batch.src_lengths, batch.trg_lengths)\n",
        "        loss = loss_compute(pre_output, batch.trg_y, batch.nseqs)\n",
        "        total_loss += loss\n",
        "        total_tokens += batch.ntokens\n",
        "        print_tokens += batch.ntokens\n",
        "        \n",
        "        if model.training and i % print_every == 0:\n",
        "            elapsed = time.time() - start\n",
        "            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" % (i, loss / batch.nseqs, print_tokens / elapsed))\n",
        "            start = time.time()\n",
        "            print_tokens = 0\n",
        "\n",
        "    return math.exp(total_loss / float(total_tokens))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg5TrL5FDcgF"
      },
      "source": [
        "### Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yChdjDEQDeAs"
      },
      "source": [
        "class SimpleLossCompute:\n",
        "    def __init__(self, generator, criterion, opt=None):\n",
        "        self.generator = generator\n",
        "        self.criterion = criterion\n",
        "        self.opt = opt\n",
        "\n",
        "    def __call__(self, x, y, norm):\n",
        "        x = self.generator(x)\n",
        "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)),\n",
        "                              y.contiguous().view(-1))\n",
        "        loss = loss / norm\n",
        "\n",
        "        if self.opt is not None:\n",
        "            loss.backward()          \n",
        "            self.opt.step()\n",
        "            self.opt.zero_grad()\n",
        "\n",
        "        return loss.data.item() * norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcsJA-ptE6IW"
      },
      "source": [
        "### Greedy decoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABuFtq81E83u"
      },
      "source": [
        "def greedy_decode(model, src, src_mask, src_lengths, max_len=100, sos_index=1, eos_index=None):\n",
        "    with torch.no_grad():\n",
        "        encoder_hidden, encoder_final = model.encode(src, src_mask, src_lengths)\n",
        "        prev_y = torch.ones(1, 1).fill_(sos_index).type_as(src)\n",
        "        trg_mask = torch.ones_like(prev_y)\n",
        "\n",
        "    output = []\n",
        "    attention_scores = []\n",
        "    hidden = None\n",
        "\n",
        "    for i in range(max_len):\n",
        "        with torch.no_grad():\n",
        "            out, hidden, pre_output = model.decode(\n",
        "              encoder_hidden, encoder_final, src_mask,\n",
        "              prev_y, trg_mask, hidden)\n",
        "\n",
        "            prob = model.generator(pre_output[:, -1])\n",
        "\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.data.item()\n",
        "        output.append(next_word)\n",
        "        prev_y = torch.ones(1, 1).type_as(src).fill_(next_word)\n",
        "        attention_scores.append(model.decoder.attention.alphas.cpu().numpy())\n",
        "    \n",
        "    output = np.array(output)\n",
        "        \n",
        "    if eos_index is not None:\n",
        "        first_eos = np.where(output==eos_index)[0]\n",
        "        if len(first_eos) > 0:\n",
        "            output = output[:first_eos[0]]      \n",
        "    \n",
        "    return output, np.concatenate(attention_scores, axis=1)\n",
        "  \n",
        "\n",
        "def lookup_words(x, vocab=None):\n",
        "    if vocab is not None:\n",
        "        x = [vocab.itos[i] for i in x]\n",
        "\n",
        "    return [str(t) for t in x]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzHwRi_iIBQz"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRWA_TMQIDWf"
      },
      "source": [
        "def train(model, num_epochs=3, lr=0.0003, print_every=100):    \n",
        "    if USE_CUDA:\n",
        "        model.cuda()\n",
        "\n",
        "    criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=PAD_INDEX)\n",
        "    optim = torch.optim.Adam(model.parameters(), lr=lr)    \n",
        "    dev_perplexities = []\n",
        "\n",
        "    for epoch in range(num_epochs):      \n",
        "        print(\"Epoch\", epoch)\n",
        "        model.train()\n",
        "        train_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in train_iter), \n",
        "                                     model,\n",
        "                                     SimpleLossCompute(model.generator, criterion, optim),\n",
        "                                     print_every=print_every)\n",
        "        \n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            print_examples((rebatch(PAD_INDEX, x) for x in valid_iter), \n",
        "                           model, n=3, src_vocab=SRC.vocab, trg_vocab=TRG.vocab)        \n",
        "\n",
        "            dev_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in valid_iter), \n",
        "                                       model, \n",
        "                                       SimpleLossCompute(model.generator, criterion, None))\n",
        "            print(\"Validation perplexity: %f\" % dev_perplexity)\n",
        "            dev_perplexities.append(dev_perplexity)\n",
        "        \n",
        "    return dev_perplexities        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_0JLdf5FC_9"
      },
      "source": [
        "def print_examples(example_iter, model, n=2, max_len=100, \n",
        "                   sos_index=1, \n",
        "                   src_eos_index=None, \n",
        "                   trg_eos_index=None, \n",
        "                   src_vocab=None, trg_vocab=None):\n",
        "\n",
        "    model.eval()\n",
        "    count = 0\n",
        "    print()\n",
        "    \n",
        "    if src_vocab is not None and trg_vocab is not None:\n",
        "        src_eos_index = src_vocab.stoi[EOS_TOKEN]\n",
        "        trg_sos_index = trg_vocab.stoi[SOS_TOKEN]\n",
        "        trg_eos_index = trg_vocab.stoi[EOS_TOKEN]\n",
        "    else:\n",
        "        src_eos_index = None\n",
        "        trg_sos_index = 1\n",
        "        trg_eos_index = None\n",
        "        \n",
        "    for i, batch in enumerate(example_iter):\n",
        "      \n",
        "        src = batch.src.cpu().numpy()[0, :]\n",
        "        trg = batch.trg_y.cpu().numpy()[0, :]\n",
        "\n",
        "        src = src[:-1] if src[-1] == src_eos_index else src\n",
        "        trg = trg[:-1] if trg[-1] == trg_eos_index else trg      \n",
        "      \n",
        "        result, _ = greedy_decode(\n",
        "          model, batch.src, batch.src_mask, batch.src_lengths,\n",
        "          max_len=max_len, sos_index=trg_sos_index, eos_index=trg_eos_index)\n",
        "        print(\"Example #%d\" % (i+1))\n",
        "        print(\"Src : \", \" \".join(lookup_words(src, vocab=src_vocab)))\n",
        "        print(\"Trg : \", \" \".join(lookup_words(trg, vocab=trg_vocab)))\n",
        "        print(\"Pred: \", \" \".join(lookup_words(result, vocab=trg_vocab)))\n",
        "        print()\n",
        "        \n",
        "        count += 1\n",
        "        if count == n:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHkSsR7GI50z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cf5ae67f-1c24-4ac6-ad4d-83846e123348"
      },
      "source": [
        "model = init_model(len(SRC.vocab), len(TRG.vocab),\n",
        "                   emb_size=256, hidden_size=256,\n",
        "                   num_layers=1, dropout=0.2)\n",
        "dev_perplexities = train(model, print_every=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Epoch Step: 100 Loss: 43.436565 Tokens per Sec: 11552.629034\n",
            "Epoch Step: 200 Loss: 118.421257 Tokens per Sec: 12491.684768\n",
            "Epoch Step: 300 Loss: 93.032379 Tokens per Sec: 12408.382354\n",
            "Epoch Step: 400 Loss: 50.549698 Tokens per Sec: 12541.160538\n",
            "Epoch Step: 500 Loss: 128.055923 Tokens per Sec: 12408.650686\n",
            "Epoch Step: 600 Loss: 50.360241 Tokens per Sec: 12488.902137\n",
            "Epoch Step: 700 Loss: 43.303864 Tokens per Sec: 12270.361040\n",
            "Epoch Step: 800 Loss: 102.230705 Tokens per Sec: 12342.316358\n",
            "Epoch Step: 900 Loss: 67.016190 Tokens per Sec: 12422.257508\n",
            "Epoch Step: 1000 Loss: 72.575668 Tokens per Sec: 12308.966880\n",
            "Epoch Step: 1100 Loss: 62.689564 Tokens per Sec: 12253.979613\n",
            "Epoch Step: 1200 Loss: 100.496254 Tokens per Sec: 12346.357204\n",
            "Epoch Step: 1300 Loss: 48.766090 Tokens per Sec: 12345.176811\n",
            "Epoch Step: 1400 Loss: 49.611462 Tokens per Sec: 12361.205638\n",
            "Epoch Step: 1500 Loss: 88.449425 Tokens per Sec: 12354.893705\n",
            "Epoch Step: 1600 Loss: 66.452560 Tokens per Sec: 12269.909304\n",
            "Epoch Step: 1700 Loss: 27.303524 Tokens per Sec: 12184.665646\n",
            "Epoch Step: 1800 Loss: 73.953819 Tokens per Sec: 12377.222584\n",
            "Epoch Step: 1900 Loss: 47.663258 Tokens per Sec: 12274.000399\n",
            "Epoch Step: 2000 Loss: 51.406826 Tokens per Sec: 12415.947271\n",
            "Epoch Step: 2100 Loss: 43.867554 Tokens per Sec: 12274.923673\n",
            "Epoch Step: 2200 Loss: 72.045593 Tokens per Sec: 12356.588911\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 20 years old , i was a <unk> of <unk> <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father was in the <unk> , the <unk> , the <unk> of the <unk> .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he 's very much in the same time , what was really good , the <unk> of the <unk> .\n",
            "\n",
            "Validation perplexity: 30.747188\n",
            "Epoch 1\n",
            "Epoch Step: 100 Loss: 80.623764 Tokens per Sec: 11954.617518\n",
            "Epoch Step: 200 Loss: 54.470089 Tokens per Sec: 12337.355802\n",
            "Epoch Step: 300 Loss: 54.247948 Tokens per Sec: 12372.986536\n",
            "Epoch Step: 400 Loss: 37.435848 Tokens per Sec: 12444.768698\n",
            "Epoch Step: 500 Loss: 17.660452 Tokens per Sec: 12402.966981\n",
            "Epoch Step: 600 Loss: 70.659752 Tokens per Sec: 12311.403321\n",
            "Epoch Step: 700 Loss: 88.492233 Tokens per Sec: 12335.922898\n",
            "Epoch Step: 800 Loss: 33.064507 Tokens per Sec: 12405.781156\n",
            "Epoch Step: 900 Loss: 66.886940 Tokens per Sec: 12349.332022\n",
            "Epoch Step: 1000 Loss: 34.418602 Tokens per Sec: 12359.839131\n",
            "Epoch Step: 1100 Loss: 46.724045 Tokens per Sec: 12457.355037\n",
            "Epoch Step: 1200 Loss: 70.785019 Tokens per Sec: 12526.087528\n",
            "Epoch Step: 1300 Loss: 59.676212 Tokens per Sec: 12485.523232\n",
            "Epoch Step: 1400 Loss: 34.496174 Tokens per Sec: 12430.087202\n",
            "Epoch Step: 1500 Loss: 64.251648 Tokens per Sec: 12465.156925\n",
            "Epoch Step: 1600 Loss: 29.760315 Tokens per Sec: 12454.230611\n",
            "Epoch Step: 1700 Loss: 30.184355 Tokens per Sec: 12316.922103\n",
            "Epoch Step: 1800 Loss: 72.565514 Tokens per Sec: 12362.297045\n",
            "Epoch Step: 1900 Loss: 22.269543 Tokens per Sec: 12291.663212\n",
            "Epoch Step: 2000 Loss: 44.464058 Tokens per Sec: 12388.696557\n",
            "Epoch Step: 2100 Loss: 75.565910 Tokens per Sec: 12382.554695\n",
            "Epoch Step: 2200 Loss: 76.652977 Tokens per Sec: 12385.952493\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was a <unk> of the <unk> of the <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father was on the <unk> , his <unk> , the <unk> of the <unk> .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw me happy , which was pretty much , the first thing is to <unk> the news of <unk> .\n",
            "\n",
            "Validation perplexity: 19.814182\n",
            "Epoch 2\n",
            "Epoch Step: 100 Loss: 28.584925 Tokens per Sec: 11907.796038\n",
            "Epoch Step: 200 Loss: 81.115669 Tokens per Sec: 12276.886047\n",
            "Epoch Step: 300 Loss: 72.485924 Tokens per Sec: 12386.797941\n",
            "Epoch Step: 400 Loss: 35.376106 Tokens per Sec: 12436.785783\n",
            "Epoch Step: 500 Loss: 26.625444 Tokens per Sec: 12410.781894\n",
            "Epoch Step: 600 Loss: 46.195351 Tokens per Sec: 12318.504554\n",
            "Epoch Step: 700 Loss: 41.344807 Tokens per Sec: 12406.486266\n",
            "Epoch Step: 800 Loss: 16.631710 Tokens per Sec: 12332.276112\n",
            "Epoch Step: 900 Loss: 33.972916 Tokens per Sec: 12459.470593\n",
            "Epoch Step: 1000 Loss: 25.037127 Tokens per Sec: 12367.924205\n",
            "Epoch Step: 1100 Loss: 28.772793 Tokens per Sec: 12431.612264\n",
            "Epoch Step: 1200 Loss: 34.887871 Tokens per Sec: 12448.659871\n",
            "Epoch Step: 1300 Loss: 14.504324 Tokens per Sec: 12503.953000\n",
            "Epoch Step: 1400 Loss: 45.542118 Tokens per Sec: 12350.038963\n",
            "Epoch Step: 1500 Loss: 25.383930 Tokens per Sec: 12327.677665\n",
            "Epoch Step: 1600 Loss: 46.624794 Tokens per Sec: 12493.891119\n",
            "Epoch Step: 1700 Loss: 33.941425 Tokens per Sec: 12269.685169\n",
            "Epoch Step: 1800 Loss: 77.844810 Tokens per Sec: 12419.622807\n",
            "Epoch Step: 1900 Loss: 65.906052 Tokens per Sec: 12339.998996\n",
            "Epoch Step: 2000 Loss: 64.351540 Tokens per Sec: 12497.576381\n",
            "Epoch Step: 2100 Loss: 60.503582 Tokens per Sec: 12260.375604\n",
            "Epoch Step: 2200 Loss: 65.190285 Tokens per Sec: 12302.612566\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was a student of the <unk> of the <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father was on his little , <unk> , the <unk> of the <unk> .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy , which was pretty much , it was the <unk> of the <unk> .\n",
            "\n",
            "Validation perplexity: 15.272604\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDm8NDJ8I_hX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "e9653ebb-9de7-4ae6-c88e-435378352d95"
      },
      "source": [
        "def plot_perplexity(perplexities):\n",
        "    \"\"\"plot perplexities\"\"\"\n",
        "    plt.title(\"Perplexity per Epoch\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Perplexity\")\n",
        "    plt.plot(perplexities)\n",
        "    \n",
        "plot_perplexity(dev_perplexities)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06eFV1ArFBNa"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWlpkgMMJMgd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6ebd33cc-c6e8-4e79-8957-1e61dab8e138"
      },
      "source": [
        "!pip install sacrebleu\n",
        "import sacrebleu\n",
        "\n",
        "hypotheses = [\"this is a test\"]\n",
        "references = [\"this is a test\"]\n",
        "bleu = sacrebleu.raw_corpus_bleu(hypotheses, [references], .01).score\n",
        "print(bleu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (1.4.10)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (1.7.0)\n",
            "100.00000000000004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fitRnpp8Sxq9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "acc95834-9198-4be7-c41b-2f3d50035ad9"
      },
      "source": [
        "len(valid_data)\n",
        "references = [\" \".join(example.trg) for example in valid_data]\n",
        "print(len(references))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgZTyWy1NxqI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ab1693a-36ac-4cfe-d07f-e7921da2d5d8"
      },
      "source": [
        "hypotheses = []\n",
        "alphas = []  # attention scores\n",
        "for batch in valid_iter:\n",
        "  batch = rebatch(PAD_INDEX, batch)\n",
        "  pred, attention = greedy_decode(\n",
        "    model, batch.src, batch.src_mask, batch.src_lengths, max_len=25,\n",
        "    sos_index=TRG.vocab.stoi[SOS_TOKEN],\n",
        "    eos_index=TRG.vocab.stoi[EOS_TOKEN])\n",
        "  hypotheses.append(pred)\n",
        "  alphas.append(attention)\n",
        "hypotheses = [lookup_words(x, TRG.vocab) for x in hypotheses]\n",
        "hypotheses = [\" \".join(x) for x in hypotheses]\n",
        "\n",
        "assert(len(hypotheses) == len(references))\n",
        "\n",
        "bleu = sacrebleu.raw_corpus_bleu(hypotheses, [references], .01).score\n",
        "print(bleu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19.14422552124958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT4GJA2KM85x"
      },
      "source": [
        "### Visualization of Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_iss3EANA5S"
      },
      "source": [
        "def plot_heatmap(src, trg, scores):\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    heatmap = ax.pcolor(scores, cmap='viridis')\n",
        "    ax.set_xticklabels(trg, minor=False, rotation='vertical')\n",
        "    ax.set_yticklabels(src, minor=False)\n",
        "    ax.xaxis.tick_top()\n",
        "    ax.set_xticks(np.arange(scores.shape[1]) + 0.5, minor=False)\n",
        "    ax.set_yticks(np.arange(scores.shape[0]) + 0.5, minor=False)\n",
        "    ax.invert_yaxis()\n",
        "    plt.colorbar(heatmap)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP1uUDg2NC2U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "1ec54687-6dd9-4e60-dcc5-e753a49c8446"
      },
      "source": [
        "idx = 5\n",
        "src = valid_data[idx].src + [\"</s>\"]\n",
        "trg = valid_data[idx].trg + [\"</s>\"]\n",
        "pred = hypotheses[idx].split() + [\"</s>\"]\n",
        "pred_att = alphas[idx][0].T[:, :len(pred)]\n",
        "print(\"src\", src)\n",
        "print(\"ref\", trg)\n",
        "print(\"pred\", pred)\n",
        "plot_heatmap(src, pred, pred_att)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src ['\"', 'jetzt', 'kannst', 'du', 'auf', 'eine', 'richtige', 'schule', 'gehen', ',', '\"', 'sagte', 'er', '.', '</s>']\n",
            "ref ['\"', 'you', 'can', 'go', 'to', 'a', 'real', 'school', 'now', ',', '\"', 'he', 'said', '.', '</s>']\n",
            "pred ['\"', 'now', 'you', 'can', 'go', 'on', 'a', 'right', '?', '\"', 'he', 'said', '.', '</s>']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEHCAYAAABLKzaMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5wcZZ3v8c83gRBIuIhB5SZBThQQNa4B1lXwjgERL4AgelxcXdQjuOttX7hyIuK63t3j7qKH6LqguwqIt6iRoAKiKJAg1wSRnHALIhBuilySzHzPH1UDnWEy3dNdM1XT+b5fr3pNV3X1r57OdH7z9FNP/Uq2iYiI/jSl7gZERMT4SZKPiOhjSfIREX0sST4ioo8lyUdE9LEk+YiIPpYkHxHRx5LkIyL6WJJ8RPQdSU+RpLrb0QRJ8rHJk3RkJ9ticpD0BGAVcFjdbWkCpaxBbOok/cb2X7TbFpODpOOBVwBTbL+67vbUbbO6GxBRF0kHA4cAO0v615antgHW19OqqMBbgdcCP5C0o+3b625QnTJc0yVJ0+tuQ/Ts98Ay4GHg8pZlEfDKGtsVXZI0D1hj+1bga8Cx9baofhmu6ZKklcAdwC/K5Ze276+3VdENSZvbXld3O5pO0g+AjSYM27WPgUv6EnCB7bMl7QD83PbedberTknyPZD0VOAA4AUUX/vvsz233lbFWEl6AXAysBvFEKYA235ane1qGkkvKh++HngK8F/l+huBO2y/t5aGlSRtBSwHnj70R1vSd4Ev2L6wzrbVKUm+S5J2oUjwLwKeA9xD0Zv/xBjjvGWk7ba/1kPbpgJPpuWci+1buo3X7yT9FngvxVDNwNB223fX1qgGk7TM9rx22yaapM2BJ9i+s2XbNgC2/1hbw2qWE6/duwVYCvyz7Xf2EGfflsfTgZcBv6EYTxwzSScAH6EYShosNxt4dg9t7Hf32/5x3Y2YRGZIeprtVQCSdgdm1NwmbK+T9GdJU2wPSno6sCewSf9u05PvkqTnAC8EDgSeCtxAMf73Hz3G3Q440/b8Ll+/Etg/vdD2JA1NkXwDMBX4DvDI0PO2f1NHu5pO0nxgIcVcdFEMc73D9pJaGwZIupziG/YTgIspOmJrbb+p1obVKEm+B5JmUiT6A4A3A9jerceYmwPX2n5Gl6+/AHiF7UwBbKP8t9oY237phDVmkpG0BUUvGeC3th8Zbf+JMnR9Q/mNdkvbn5Z05aZ8rizDNV2StAzYAvgVxeyaA23f3EWc1hkLU4G9gLN7aNoq4EJJP2LDXunne4jZl2y/pO42TCaSXmr7fEmvH/bUHpKw/Z1aGrYhSXo+8CbgbeW2qTW2p3ZJ8t072PZdFcT5bMvj9cDNtlf3EO+WcplWLtGGpPeNsPl+4HLbV050exrsRcD5wEhXkZpiuKtufw98CPiu7eWSngaM9o2t72W4pkuStqU4wXlguennwCndzJWX9GQeOwF7WevsgDqV7/FkiuEo6O09bgEcDsxmw1k/p/Tc0B5J+gYwD/hBuelQ4GqKtn7L9qdralplypOQXwKebHsfSc8GDrP9TzU3rRKSPgSca/uKutvSNEnyXZL0beBa4Ixy0/8EnmN7+FfZdnHeAHwGuJDiJNYBwAdtn9Nlu3YA/gF4JsVsHQC6GV+u6j2Wsc6l7B2z4TTFz401VtUkXQQcYvuBcn0m8CNgPkVvftJfTCPp58AHgdNsP7fcdq3tfbqM9yoe/xmr7Q+2pKOAgymmM19FMaPmPNv31tWmpshwTff2sH14y/pHJXXz1f7DwL5DvfcySf8U6CrJA/8NnEXRG30n8NdAt8NKVb1HgF26nTE0AZ5Ey/kLYB1Fj/chSY04oViBrWxfNqz6blcn5yX9X2Ar4CXAV4AjgMt6bmEPbJ9F8blH0nMp/kB/p7xm5KcUvfxa21iX1K7p3kOSXji0Ul41+VAXcaYMG565m95+L08sp3Gus/1z238DdDtLpKr3CPArSc/q8rXj7b+BSyV9RNJHKKbefUPSDGBFvU2rzBpJe1Ce5Jd0BNBt4a6/sv0W4F7bHwWeDzy9mmb2zvYVtj9Rnlg/lOIq2LfX3KzapCffvXcBZ5Tj1gD3UvSax+rHkpYA3yzXjwIW99CuoRost5dfqX8PbN9lrHcCX6vgPUIx1fStklZR9JqHSgfUfpGW7Y9J+jFFeQqAd9peVj7ul/nV76aY276npNuAG+n+vT1c/nxQ0k4UV3vv2HsTe1OWNZhj+6qWzdsBl9j+dk3Nql3G5LtUnkg8AtiD4oN0P0XSGtO4pKT3ALfy2MnNX9j+bg/tOpRiSueuwL9RlM092fYPRn3hyLGGZp3MLH8+QJezTiTtRnGBytD7vIii1s+Yp52W8Z4AzGHDMeGLxhhjG9t/lDTiH0Hb93TTtiZq+bzOpvij/0e6+LyWsf43xWfrZcCpFN8Ovmx7QWUN7kJ5jclvgWfb/nO57TzgH1v+aG9yMlzTve9TTCV7GLiNIgH+uYs4T6I48boLcB7wvR7bdSTFH+9ry6+rrwBe12WseRS9+W2AbYF3UIx1flnSP4wx1muBrwOzgB3Kx11VLZT0doo/EkuAj5Y/T+4i1DfKW8StoSg5PLRcXv4cS5u2l/SPkt43VC+lYYY+r+sovt11+3mFIpEOlL3jU4FL6P1z27OyKNl3Ka5gHioguMOmnOABsJ2li4XiqtSqYomifvmZwErgnylOenYT64pOtnUY6yJgZsv6TIpplFsCK8YY62pgRsv6DODqLtt1DUUP/spyfU/gO3X+LinmYv8z8DmKMeCnjcfnrs732Pq7LH++sHzfrwIurfs9tnwWLiofnwS8p+421b1sMj15SRdIOl9St7NWhqvsRKKLT+QfymU9xbDGOZK6mZ89pRzKAIoeJt2fe9norJNh2zshWqZOlo+7vdHyw7YfhmIYwvZvga7KQJQul7Rv+91G9UTb/2j7/cD7gJ9LukbSQZLGfAVzkz+vPPZ7fBXFMM2PaMiFd+VnQeV1AUdTfGPcpG1KJ16PpRg7HGizX6deCBwr6UZ6OJEo6e+At1AMGXyFYo78OklTKIqejXVY5HPAryV9q1w/Evj4GGMMGZp18v1y/dV0P+vkP8tYQ+cbXgt0W8xtdVnI7XvATyTdC3Q1tl/aH3iTpJsphjC6+V3+SdJs2zfZXlIOFexEcbL6mi7adCwVfF4lXVPG2YzqTnzfJuk0iqHAT5Xj/ZV2GCU9xfYfunz5f1D8X7rGmSe/6Zx4LZOxgbts719BvBELkXmMJxIlfRT46kivk7SX7eu6aNvePDZt8nzbXU8DVHE7taFZJxe7h/FNFVUfh6Zk/sIVXJ2o4kYW21LMg17bZYyef5eSnlG8xL/rpg0jxKvk87qx9zZkrJ/XMuZWFOdmrrF9g6QdgWfZPq/LZo50jB/ZflWXr92KYnro4bZ/WlWbJqtNJslHRGyKNpkx+YiITdEmm+QlHZdY9cSqOl5iJdZExJusNtkkD1T5AUiseuMlVmJNRLxJaVNO8hERfa/vTrxO3266Z+y4ddv9Hr7vYaZvN330fe4a/fkh6x/+M5tNH/0+xpvd82BHsdb6EaZpi9F3mtrZjW7WDj7EtClbjrqP13dWiHAdj7A5bdo1BlXGS6zE6jben7h3je0dejnOK18yw3ff09lM18uvfmSJJ7gaa9/Nk5+x49bMP/21lcS64Yt7VRIH4AlnV3cvgynbtv8j1qmBu6srz+KBqi5BiJgYP/U5vVxfAcDd9wxw2ZKndrTv1B1vmNXr8caq75J8RMREMjDIYN3N2Kgk+YiIHhizzs39FpskHxHRoyb35CfN7BpJN0maLenCutsSETHEmAF3ttQhPfmIiB4N0txZipMpyd9FUZGvb+7WExGTX1EqNEm+Z7aH6n2/fvhz5eXLxwFs9ZSZw5+OiBhX6cmPM9sLKW5SzBP32qG5/9oR0XcMrGvwRaV9keQjIupinOGaiIi+ZRhobo5Pko+I6EVxxWtzJclHRPREDHR9T/rx13dJfv1Nm3HPW3sqKveozZ5V3XcwP2tOZbHWb17dNWybbdlZpc1ODd65prpYDz9SWSzc5L5WTGbFidck+dgEVJngIyaLYp58knxERN8aTE8+IqI/pScfEdHHjBhocK3HCWmZpF+N8tx2kv5Xm9e33Scioi6DVkdLHSYkydv+q1Ge3g5ol8A72SciYsIZsdZTO1rqMCHDNZIesD1T0geBNwBbAN+1/RHgk8Aekq4EfgI8BBxWvnQH4Dxgy9Z9bH9wItodEdFOcTFUNf1lSfOBLwBTga/Y/uSw558KnEHR8Z0KnGh78WgxJ2xMXtJBwBxgP0DAIkkHAicC+9ie27L7AknbAb8A/h24e4R9WmM/WoVy+mbbjN+biIgYQRUnXiVNBU4FXgGsBpZKWmR7RctuJwFn2/6SpL2BxcDs0eJO5InXg8rlinJ9JkXSv2X4jpIE/BfweduXS5o9WuDWKpTbbrljg6tIRES/scWAK+nJ7westL0KQNKZwGuA1iRvYKgnuy3w+3ZBJzLJC/iE7dM22DhyAj8ZWG37P8e/WRERvRnsvCc/S9KylvWFZScVYGfg1pbnVgP7D3v9ycB5kk4AZgAvb3fAiUzyS4CPSfpv2w9I2hlYB/wJ2HpoJ0mvpmj4S1peu8E+ERFNUZx47TiVrrE9r4fDvRE43fbnJD0f+LqkfeyN1+2YqCRv2+dJ2gv4dTEawwPAm23/P0kXS7oW+DEwj+Iv2mXlfotsL2jdJydeI6IpKjzxehuwa8v6LuW2Vm8D5gPY/rWk6cAs4M6NBR33JC/piZT3ZbX9BYozxxuwfUy7OJ3sExFRh4Fq5sAvBeZI2p0iuR8NDM97twAvA04vO83TKe5/vVHjmuQl7QRcCHx2PI8TEVGXqq54tb1e0vEUQ9tTga/aXi7pFGCZ7UXA+4EvS3ovxZeIY+3R7z04rkne9u+Bp4/nMR5nihicsUUloe7Yr7or1Oa8/+bKYv3uvmpKKQNsd8K0ymIxWPHEppQHjklisJrZNZRz3hcP27ag5fEK4AVjiZnaNRERPSgKlDW3dk2SfERED4xYV1PJgk4kyUdE9MCmqouhxkWSfERETzSWi6EmXFd/fiTNLuesTxhJcyUdMpHHjIhoxxQ9+U6WOjT3O8bjzQWS5COicQaY0tFSh56PKulpkq6QtL+kX5ePfyXpGeXzx0r6jqRzJd0g6dMtr31A0sclXSXpEklPLrcfKenacvtFkqYBpwBHSbpS0lG9tjsiogqmsxuG1HXTkJ7G5MtEfiZwLHAjcEA5of/lwD8Dh5e7zgWeCzwCXC/p32zfSlFg5xLbHy6T/98C/wQsAF5p+zZJ29leK2kBMM/28SO047FSw9O27eUtRUSMiYF1ndeumXC9tGwH4PvA622vkLQrcIakORTve/OWfX9m+34ASSuA3Siqra0FfljuczlFHWWAiyku2z0b+E67hmxQanjGTik1HBETSI2+kXcvwzX3U9RReGG5/jHgAtv7AK+mqKkw5JGWxwM89sdlXcsluY9ut/1OiuL4uwKXl/VvIiIaxxRXvHay1KGXnvxa4HXAEkkPUBSwH6qYdmwvjZK0h+1LgUslHUyR7FNuOCIaqV978tj+M3Ao8F7gSuATkq6g9/n3n5F0TTlN81fAVcAFwN458RoRTWKr/3rytm8C9ikf3wfsWz710ZbdTiqfPx04veW1h7Y8ntny+BzgnPLx60c47D0tx4mIaITixGvKGkych9fCdasqCTXnlOp+cXfu9OTKYm23fqCyWIxepXRMpuz8FHzX3ZXFY+3a6mI1taKlKuzdNfU99r3K7vE6LvovyUdtKk3wEZNEceK1uWPySfIRET1qcqnh5rYsImISqPKKV0nzJV0vaaWkE0d4/l/KySdXSvqdpPvaxUxPPiKiR1XcyFvSVOBUiotCVwNLJS0q7wYFgO33tux/AkUlgVE1sicv6WRJH6i7HRER7diwbnBKR0sb+wErba+yvZaiZMxrRtn/jcA32wVNTz4iogfFcE3H/eVZkpa1rC8sy7IA7ExR7mXIamD/kYJI2g3YHTi/3QEbk+QlfRj4a+BOijd6uaQLgQ/YXiZpFsUdy2fX18qIiMcbwxWva2zPq+CQRwPn2G47n7oRSV7S8ygaPZeiTb+hKFjW6esfq0KpGePRxIiIEVU4hfI2ihIuQ3bhsVIxwx0NvLuToI1I8sABwHdtPwggadFYXrxBFcqps1KFMiIm0JiGa0azFJgjaXeK5H40cMzjjibtCTwB+HUnQRt54rXFeh5r4/TRdoyIqMtgeZ/XdstobK8HjgeWANcBZ9teLukUSYe17Ho0cGZLBd9RNaUnfxFF/fhPULTp1cBpwE3A84DLgCNqa11ExEYUs2uqKYFiezGweNi2BcPWTx5LzEb05G3/BjiLotrkjym+tgB8FnhXWdlyVk3Ni4jYqL6+/V+VbH8c+PgITz275fFJE9SciIiOtRuKqVNjknxExGSUAmUTzYb16ysJNbh2XSVxAKauubeyWGwxrbJQd82fXVmse579lMpiATzjs7e236lDA7f/obJYVdK06n6Xgw89VFmsGJu6bgjSif5L8hERE8gW65PkIyL6V4ZrIiL6VMbkIyL6XJOTfHMHkoaRtIOkSyVdIemAutsTEQGZJ1+llwHX2H573Q2JiGjV5HnytfbkJX1P0uWSlpeVJJH0QMvzR0g6XdJc4NPAa8rbXm1ZV5sjIlrZsH5wSkdLHeruyf+N7XvKpL1U0rdH2sn2lZIWAPNsHz/8+Q1KDbPVuDY4ImK4Jo/J153k3yPpdeXjXYE53QTZoNTwlCem1HBETJihMfmmqi3JS3ox8HLg+bYfLO8CNZ1iRtKQlBeOiMZzg5N8nWPy2wL3lgl+T+Avy+13SNpL0hTgdRt/eUREM1RRT3681JnkzwU2k3Qd8EngknL7icAPgV8Bt9fUtoiIjthUNoVS0nxJ10taKenEjezzBkkrygkr32gXs7bhGtuPAAdv5OlzRtj/dOD0cWxSREQXxEAFM2ckTQVOBV4BrKaYjLLI9oqWfeYAHwJeYPteSU9qF7fuE6+Vs83g2rV1N+Nx1t99d91NGNEO36/u32qH78PA7jtVFu/OV+5WWawn/aC69zlwz32VxaqyCiWpQlmbisbk9wNW2l4FIOlM4DXAipZ9/hY41fa9xXF9Z7ugk+aK12i+KhN8xGQxVLumw+GaWZKWtSzHtYTaGWitr7263Nbq6cDTJV0s6RJJ89u1r+968hERE8rFuHyH1tie18PRNqOYav5iYBfgIknPsr3Rr5fpyUdE9Kii2TW3UVwvNGSXclur1cAi2+ts3wj8jjbXFyXJR0T0wOWJ106WNpYCcyTtLmkacDSwaNg+36PoxSNpFsXwzarRgtaW5CUtlrRdXcePiKiK3dkyegyvB44HlgDXAWfbXi7pFEmHlbstAe6WtAK4APig7VFnddQ5hfKQuo4dEVGlqq54tb0YWDxs24KWxwbeVy4dmZCevKQ3S7qsrCB5mqSpkm6SNEvSbEnXSfpyObn/vKEqk5L2kHRuWanyF+WVsRERjVH00tXRUodxT/KS9gKOopi8PxcYAN40bLc5FHM/nwncBxxebl8InGD7ecAHgC9u5BjHDU1JWscj4/E2IiI2alO/acjLgOdRXL0FsCUwfAL/jbavLB9fDsyWNBP4K+Bb5esAthjpAK1VKLfR9qlCGRETagxTKCfcRCR5AWfY/tAGG6VjW1Zbu98DFH8IpgD3lb3/iIhGMmKwphuCdGIiWvYz4IihGguStpfU9np1238EbpR0ZPk6SXrO+DY1ImLs3OFSh3FP8mVxnZOA8yRdDfwE2LHDl78JeJukq4DlFHUcIiKao+EnXidkCqXts4Czhm2eXf5cA+zTsu9nWx7fCLStzRARUatNfEw+IqKvNfnOUP2Z5FXRKJQHq4kD1bWpatttU1mogZmbVxYL4O791lcWa+nHflpZrJe87e2Vxdpq2Y2VxdpkVPl/qYIeuIHBwST5iIj+ZCA9+YiI/rWpz5OPiOhvSfIREf2qvumRnRjzGYx2JYIlnS7piBG2z5Z0TMv6PEn/OtbjR0Q0ToOvhhpTT15FEZlD7a6mncwGjgG+AWB7GbCsizgREc1hcINn17TtyZc98OslfQ24Fhgo70iCpLdIulrSVZK+3vKyAyX9StKqll79J4EDynLD75X0Ykk/LOPsIOknZanhr0i6ueUYjytTXOm/QEREz9Th0iaKNL/MtyslnTjC88dKuqvMh1dKajuft9PhmjnAF8tSwDeXB3smRbmCl9p+DvB3LfvvCLwQOJQiuQOcCPzC9lzb/zIs/keA88v45wBPLY/RSZnilBqOiHpVMFxTdmBPBQ4G9gbeKGnvEXY9q8yjc21/pV3TOh2uudn2JcO2vRT4lu01ALbvaXnue+WQzgpJT+4g/guB15VxzpV0b7m9kzLFKTUcEfWqJuvsB6y0vQpA0pkU9bpW9BK00yT/5zHGbe1O9zJYNWKZ4oiIxhjbxVCzJLWei1xYdlIBdgZubXluNbD/CDEOl3Qg8DvgvbZvHWGfR/VyffD5wJGSnghFCeE2+/8J2Hojz10MvKGMcxDwhHJ7V2WKIyIm0hhu5L3G9ryWZWGb0MP9AJht+9kUFX3PaPeCrpO87eXAx4Gfl6WAP9/mJVdTnLS9StJ7hz33UeAgSdcCRwJ/AP7UY5niiIiJMajOltHdBuzasr5Lue1Rtu+2PTRS8hWK4exRtR2usX0TG5YCnt3y+AyG/SWxfeyw9Znlz3UU4/itLix/3g+80vZ6Sc8H9h16IxspUxwR0RiqZkx+KTBH0u4Uyf1oimnnjx1H2tH27eXqYcB17YI25YrXpwJnS5oCrAX+tpdgmlLNnFUPVBKmDNbMipaD22xZWazN7n8YPVxd5ci9PrW2sliHvP8FlcWac35P58E2cOs7Z1cWi7vWVBeryar8v1SFii50Kju5xwNLgKnAV20vl3QKsMz2IuA9kg4D1gP3AMe2i9uIJG/7BuC5dbcjelNlgo+YPFRZFUrbi4HFw7YtaHn8IWBME1EakeQjIia1Bk/cTpKPiOhVw0aQWiXJR0T0ouE3DRnXe9KVdRb+fYyvOVnSB8arTRERVZM7W+qQnnxERK8aPCbfVU9e0gxJPyovbLpW0lGS9i0rT15VVo0curp1J0nnSrpB0qdbYjzQ8vgISaePcJw9ytdeLukXkvbspr0REZuqbnvy84Hf234VgKRtgSuAo2wvlbQN8FC571yK6ZGPANdL+rd2tRZaLATeafsGSfsDX+TxF1Qh6TjgOIDpbNXlW4qI6E5dQzGd6DbJXwN8TtKngB8C9wG3214KYPuPAGXlyJ/Zvr9cXwHsxoZFeEYkaSbwV8C3yjgAW4y0b6pQRkRtTCclC2rTVZK3/TtJfwEcAvwTRbGyjWmtSDnQcszWZDx9hNdNAe4r68hHRDRXg7uW3Y7J7wQ8aPu/gM9QlMPcUdK+5fNbS2r3B+QOSXuVpQxeN/zJ8tvAjZKOLGNK0nO6aW9ExHjqx9k1zwI+I2kQWAe8i6L2+79J2pJiPP7lbWKcSDHUcxfFvV5njrDPm4AvSToJ2Bw4E7iqyzZHRIyPBvfkux2uWUJRRGe4vxy2fnq5DL3u0JbH51Dc6m947JNbHt9IcZI3IqK5+i3JR0REoc6hmE70XZKXhKZOrSSWB6v7zVXVJqiulDLAwMwRJyx1ZbObb2+/0xhU+e8/8OcHK4u1+mUzKovFnOpCTZk2rbJYg2urK/O8Sei32TUREfGYJvfkx7V2TUTEJsEdLm1Imi/pekkrJZ04yn6HS7Kkee1iJslHRPSiw+mT7Xr7kqYCpwIHA3sDb5S09wj7bQ38HXBpJ81Lko+I6FU1Pfn9gJW2V9leSzFl/DUj7Pcx4FPAw500bcKSvKTTJR0xUceLiJgoGuxsAWZJWtayHNcSZmc2LPmyutz22HGKSgO72v5Rp23LideIiImzxnbbcfSRlNUBPk8HN+9u1VNPXtL/Lk8S/FLSNyV9oE154APLcsSrWnv1kj4oaamkqyV9tNw2W9J1kr4sabmk88qraSMimqWa4ZrbgF1b1ncptw3ZGtgHuFDSTRQXny5qd/K16yRf1qk5HHgOxYmCoQMtBE6w/TzgAxTlgYfsCLwQOBT4ZBnnIIrZwvtRlCV+nqQDy/3nAKfafiZFpcvDN9KW44a+/qx1R8NUERHVqOjEK7AUmCNpd0nTgKOBRY8exr7f9izbs23PBi4BDrO9bLSgvQzXvAD4vu2HgYcl/YCimuRo5YG/Z3sQWCHpyeW2g8rlinJ9JkVyvwW40faV5fbLgdkjNaS11PC2U57Y4BmrEdGXKsg6ttdLOp6iZMxU4Ku2l0s6BVhme9HoEUZW9Zh8u/LArWWH1fLzE7ZPa91R0mweX6Y4wzUR0TwVdS1tLwYWD9u2YCP7vriTmL2MyV8MvFrS9PIGH4cCDzL28sBLgL8pYyBpZ0lP6qFdERETRoxpds2E67onX97mbxFwNXAHxd2i7meM5YFtnydpL+DX5RDPA8CbKXruERHN1ucFyj5r+2RJWwEXAZdvrDyw7WOHrc9sefwF4AsjxN+nZZ/P9tjWiIjx0cdJfmF52e104Azbv6mgTT2xzeC69RUFq+77lddXGKuySKBfVncPlqq/elVZbbPK3yWbV3cqa+321Z1m2nygmV9+tdnmdTdh49ZVFKdfk7ztY6pqSETEZNXPwzUREZEkHxHRp1zfzJlOJMlHRPQqPfmIiP6VMfmIiH6WJB8R0ac6vLVfXfoiyZeF948DmM5WNbcmIjYlIsM14661CuU22r7B/9wR0Y+S5CMi+lmDk/yku5G3pJ9J2rn9nhERE6SaO0ONi0mV5Mt7HP4P4J662xIRAVR5ZygkzS9vqbpS0okjPP9OSddIurK87ere7WJOqiQP7A182/ZDdTckIuJRFfTkJU0FTqW4nerewBtHSOLfsP2s8sZMn6a4sfeoJlWSt32t7ffV3Y6IiFYV3TRkP2Cl7VW211Lci+M1rTvY/mPL6gw6GATqzxOvVZaV7XcN/rfyYDP7IIP3/08YPXkAAAlQSURBVLH9Th1au211/wWn77pLZbEGb7+jsljacnplsQAG9p5dXbCLqwkzhtk1syS13nh7YTk7EGBn4NaW51YD+z/uWNK7gfcB04CXtjtgfyb5iIiJMraTqmtsz+vpcPapwKmSjgFOAv56tP2b2VWKiJhMqpldcxuwa8v6LuW2jTkTeG27oEnyERE9GLritYLZNUuBOZJ2lzQNOBpYtMGxpDktq68CbmgXNMM1ERE90mDvk+Btr5d0PLAEmAp81fZySacAy2wvAo6X9HKKGxfeS5uhGphESV7STcCLgdNtv7jWxkREDKnwQifbi4HFw7YtaHn8d2ONOWmSfEREU6V2TTXuAgbI1a4R0TRJ8r2zvW/58PXDn0up4YioU5N78n0xu8b2QtvzbM/bnC3qbk5EbGoaXKBs0vTkIyIayR2VLKhNknxERA9yZ6iIiH7n5mb5JPmIiB6lJx/RjYZWyHQFVzcO2fr6eyuLdfPnZ1YWa/PNtqws1k7/MFBZrEaq8aRqJ5LkIyJ6lBOvERF9LEk+IqJfmZx4jYjoZ00+8dqoK14lzZV0SN3tiIgYkwZf8dqoJA/MBZLkI2LSqPCmIeOisiQvaYakH0m6StK1ko6StEDS0nJ9oSSV++4r6WpJV0r6TPn8NOAU4Khy+1FlzK9KukzSFZJeM3orIiImmI0GO1vakTRf0vWSVko6cYTn3ydpRZk/fyZpt3Yxq+zJzwd+b/s5tvcBzgX+3fa+5fqWwKHlvv8JvMP2XIrywdheCywAzrI91/ZZwIeB823vB7wE+IykGcMPLOk4ScskLVvHIxW+pYiIDlQwXCNpKnAqcDCwN/BGSXsP2+0KYJ7tZwPnAJ9u17Qqk/w1wCskfUrSAbbvB14i6VJJ1wAvBZ4paTtga9u/Ll/3jVFiHgScKOlK4EJgOvDU4TulCmVE1Kmi4Zr9gJW2V5Wd3jOBDUYvbF9g+8Fy9RKKm32PqrLZNbZ/J+kvKMbU/0nSz4B3U/zVuVXSyRRJeiwEHG77+qraGRFRKQOdXwU9S9KylvWFtheWj3cGbm15bjWw/yix3gb8uN0BK0vyknYC7rH9X5LuA95ePrVG0kzgCOAc2/dJ+pOk/W1fSnFH8iF/ArZuWV8CnCDpBNuW9FzbV1TV5oiISnR+UnWN7Xm9Hk7Sm4F5wIva7VvlPPlnUYyZD1LcSfxdwGuBa4E/AEtb9n0b8OVy358D95fbL+Cx4ZlPAB8D/g9wtaQpwI08Nq4fEdEIFc2cuQ3YtWV9l3LbhseSXk5xvvJFttuehKxyuGYJRc+71TLgpBF2X16eOKA8g7ysjHEPsO+wfd9RVRsjIsZDJzNnOrAUmCNpd4rkfjRwzAbHkZ4LnAbMt31nJ0HruuL1VZI+VB7/ZuDYmtoREdGbii50sr1e0vEUneWpwFdtL5d0CrDM9iLgM8BM4FvljPRbbB82Wtxaknw5PfKsOo4d0ST604Ptd+rQdt/cubJYj2xb3cS7P+5dbanhzR9oVuni4mKoasZrbC8GFg/btqDl8cvHGjO1ayIiepUqlBER/auqnvx4SJKPiOhF7gwVEdHPOqtLU5ck+YiIXmW4plqSptpu1in2iNg0udm3/2taPXmguGS3LC98paTTJE2V9ICkz0m6Cnh+3W2MiHiU3dlSg8YleUl7AUcBL2gpRfwmYAZwaVnK+JfDXpNSwxFRnwbfGaqJwzUvA54HLC2v6NoSuJMi2X97pBeUVdwWAmyj7Zs7OBYRfUmDzR2vaWKSF3CG7Q9tsFH6QMbhI6JxTKMvhmrccA3wM+AISU8CkLR9J7e4ioiogzByZ0sdGteTt71C0knAeWV54XUUNx+JiGimTKEcm40UMJtZR1siItpKko/oI65uAHb9LY+7J0TXtrnnvspiMXVqZaH+cMzwe1H3ZsfFf6g0Xs8aPiafJB8R0aPMromI6Fv1XejUiSbOromImDxMZVe8Spov6XpJK8tbow5//kBJv5G0XtIRnTQvST4ioleDHS6jkDQVOBU4GNgbeKOk4Sc0bqG4Xeo3Om1ahmsiInpU0Rz4/YCVtlcBSDoTeA2wYmgH2zeVz3V8EiA9+YiIXnU+XDNrqM5WuRzXEmVn4NaW9dXltp6kJx8R0QsbBjruWK+xPW88mzNcXyT58q/hcQDT2arm1kTEJqea4ZrbgF1b1ncpt/WkL4ZrbC+0Pc/2vM3Zou7mRMSmpprZNUuBOZJ2lzQNOBpY1GvT+iLJR0TUxsCgO1tGC2OvB44HlgDXAWfbXi7pFEmHAUjaV9Jq4EjgNEnL2zWvL4ZrIiLq48pKXdheDCwetm1By+OlFMM4HZtUPXlJiyXtVHc7IiIeZYoTr50sNZhUPXnbh9TdhoiIx2lwWYNJleQjIhopST4ixt3m1f131hbVzVKbUvFNO1e9tefrgx6zoP0u7TW7QFmSfERELwyk1HBERB9LTz4iol+NqazBhEuSj4johcEV3hKyarXNk5d0tKQP13X8iIjKVHDF63iZsCQvaZqkGS2bDgbO7XDfiIjmqujOUONh3JO8pL0kfQ64Hnh6uU3AXOA3kl4k6cpyuULS1sATgOWSTpO073i3MSKia3Yxu6aTpQbjkuQlzZD0Vkm/BL5McWeTZ9u+otzlucBVtg18AHi37bnAAcBDtu8AngFcAHy8TP7vkbT9Ro533FAR/nU8Mh5vKSJi4xrckx+vE6+3A1cDb7f92xGenw/8uHx8MfB5Sf8NfMf2agDbjwBnAmdKeirw78CnJT3N9u9bg9leCCwE2EbbN3cuU0T0IeOBiq/4qtB4DdccQVHs/juSFkjabdjzBwHnAdj+JPB2YEvgYkl7Du0k6UmS3g/8AJgKHAPcMU5tjogYu4pKDY+XcenJ2z4POE/SE4E3A9+XtIYimd8LbGb7bgBJe9i+BrimHH/fU9LtwBnAnsDXgUNs93yHlIiIcdHgKZTjOk++TORfAL4gaT9gAHgF8NOW3f5e0kuAQWA5xTDOdOBfgQvKcfuIiEYy4Jp66Z2YsIuhbF8GIOkjwFdatp8wwu6PAOdPUNMiIrrn6m4aMh4m/IpX22+f6GNGRIynJp94Vb+Nhki6C7i57nZExKSwm+0degkg6VxgVoe7r7E9v5fjjVXfJfmIiHjMpLrHa0REjE2SfEREH0uSj4joY0nyERF9LEk+IqKP/X+50YEtCyllKQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlPu4yuWUCMo"
      },
      "source": [
        "## Wrap-up\n",
        "\n",
        "Now you know all the nitty-gritty of the Encoder-Decoder architecture implemented using RNNs and attention mechanism. \n",
        "\n",
        "Here are some suggestions how to improve the model:\n",
        "- train for more epochs (now `num_epochs` is set to 3 but you can try with for example `num_epochs=10` and see if the perplexity and bleu scores improve)\n",
        "- use BPEs\n",
        "- use beam search instead of greedy decoding\n",
        "- add more layers to encoder/decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnHtMivwGSpB"
      },
      "source": [
        "## References\n",
        "* BPE - [paper](https://arxiv.org/abs/1508.07909) and [code](https://github.com/rsennrich/subword-nmt)\n",
        "* BLEU - [paper](https://www.aclweb.org/anthology/P02-1040/) and [code](https://github.com/moses-smt/mosesdecoder/blob/master/scripts/generic/multi-bleu.perl)\n",
        "* Attention - [additive](https://arxiv.org/abs/1409.0473) and [multiplicative](https://arxiv.org/abs/1508.04025)\n"
      ]
    }
  ]
}