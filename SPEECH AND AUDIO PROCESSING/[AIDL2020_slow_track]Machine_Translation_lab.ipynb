{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "[AIDL2020 slow-track]Machine_Translation_lab.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8EvKKcc-mL0"
      },
      "source": [
        "#Introduction\n",
        "\n",
        "This lab is devoted to **Neural Machine Translation.**\n",
        "\n",
        "Today we will train and evaluate RNN Encoder-Decoder with Attention."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOW30qYBBK_w"
      },
      "source": [
        "# RNN Encoder-Decoder with Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t8P-WMyBj8z"
      },
      "source": [
        "## Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f61dHoYyBeTh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70aff78c-4912-4b2a-c11d-71f39bc2b01c"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import math, copy, time\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE=torch.device('cuda:0')\n",
        "print(\"CUDA is available:\", USE_CUDA)\n",
        "print(\"Which device:\", DEVICE)\n",
        "\n",
        "seed = 1234\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available: True\n",
            "Which device: cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_i9DppY_ZqUJ"
      },
      "source": [
        "We will use [spacy](https://github.com/explosion/spaCy) for tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK7aglukvNos",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07c3cab9-8bb1-4272-cc83-f1b4e35448d7"
      },
      "source": [
        "pip install torchtext==0.4.0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n",
            "\r\u001b[K     |██████▏                         | 10kB 24.4MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 20kB 22.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 30kB 26.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 40kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 51kB 11.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (1.15.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (1.6.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.4.0) (2.23.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.4.0) (0.16.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.4.0) (3.0.4)\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed torchtext-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snmDQ9DWFO_u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff8eea3c-df96-4eab-83cd-9c1337c9853e"
      },
      "source": [
        "!pip3 install git+git://github.com/pytorch/text spacy \n",
        "!python -m spacy download en\n",
        "!python -m spacy download de"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/pytorch/text\n",
            "  Cloning git://github.com/pytorch/text to /tmp/pip-req-build-ll7fykd6\n",
            "  Running command git clone -q git://github.com/pytorch/text /tmp/pip-req-build-ll7fykd6\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+97e6d1d) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+97e6d1d) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+97e6d1d) (1.6.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.9.0a0+97e6d1d) (1.18.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (50.3.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+97e6d1d) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+97e6d1d) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+97e6d1d) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.9.0a0+97e6d1d) (3.0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.9.0a0+97e6d1d) (0.16.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.3.1)\n",
            "Building wheels for collected packages: torchtext\n",
            "  Building wheel for torchtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchtext: filename=torchtext-0.9.0a0+97e6d1d-cp36-cp36m-linux_x86_64.whl size=6980403 sha256=e3b1c4767ece4277e46d4837df708c18254324b3f0d07a6818f4bf8be364fab9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_jahxt_e/wheels/39/42/ff/82f5ccbb0f30b25e14610376f5d0c67913fc05017dab59f8eb\n",
            "Successfully built torchtext\n",
            "Installing collected packages: torchtext\n",
            "  Found existing installation: torchtext 0.4.0\n",
            "    Uninstalling torchtext-0.4.0:\n",
            "      Successfully uninstalled torchtext-0.4.0\n",
            "Successfully installed torchtext-0.9.0a0+97e6d1d\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.3.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Collecting de_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 14.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.3.1)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp36-none-any.whl size=14907056 sha256=95f959de4e78b84901a3a4bb839c4ad3b3824d34ab6a2b5fbb145eb5607dc91c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-omwfh7ju/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwmChUernDpd"
      },
      "source": [
        "## Data\n",
        "Machine Translation dataset is a parallel (bilingual) corpus. Which means it is a dataset created out of source language sentences with their corresponding target language translations. We need to take care of two things:\n",
        "* source language vocabulary and target language vocabulary\n",
        "* source sentences and their translations (target sentences) may have different lenghts => variable-length sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miEwqs_Ve0xd"
      },
      "source": [
        "###Exercise 1: Preprocessing\n",
        "\n",
        "We will download, lowercase and tokenize the IWSLT data for the English-German language pair.\n",
        "\n",
        "As we want our model to perform fast, we only include words that occur min 5 times as well as limit the length of sentences to max 25 words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-YoawDlgF5j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db1236f6-b26f-4b90-d4eb-caa423234773"
      },
      "source": [
        "import spacy\n",
        "from torchtext import data, datasets\n",
        "\n",
        "SOS_TOKEN = \"<s>\"\n",
        "EOS_TOKEN = \"</s>\"\n",
        "UNK_TOKEN = \"<unk>\"\n",
        "PAD_TOKEN = \"<pad>\"\n",
        "MIN_FREQ = 5  # min number of times a word occurs\n",
        "MAX_LEN = 25  # max number of words per sentence\n",
        "\n",
        "spacy_de = spacy.load('de')\n",
        "spacy_en = spacy.load('en')\n",
        "\n",
        "def tokenize_de(text):\n",
        "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "SRC = data.Field(tokenize=tokenize_de, batch_first=True, lower=True, include_lengths=True,\n",
        "                  unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=None, eos_token=EOS_TOKEN)\n",
        "TRG = data.Field(tokenize=tokenize_en, batch_first=True, lower=True, include_lengths=True,\n",
        "                  unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=SOS_TOKEN, eos_token=EOS_TOKEN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbyRWNoUfkSN"
      },
      "source": [
        "####Exercise 1.1: Split data to training, validation and test datasets\n",
        "\n",
        "Use `datasets.IWSLT.splits` [method](https://torchtext.readthedocs.io/en/latest/data.html#torchtext.data.Dataset.splits). \n",
        "\n",
        "Execution of this cell will take a while."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H3yar0SFfTM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35ad6fa8-7a81-4797-afa2-03d2ee0546cb"
      },
      "source": [
        "train_data, valid_data, test_data = datasets.IWSLT.splits(\n",
        "    exts=('.de', '.en'), fields=(SRC, TRG), \n",
        "    filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and len(vars(x)['trg']) <= MAX_LEN)#TODO"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading de-en.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "de-en.tgz: 100%|██████████| 24.2M/24.2M [00:03<00:00, 6.24MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".data/iwslt/de-en/IWSLT16.TED.tst2013.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.dev2010.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2012.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.dev2012.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2014.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2010.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2014.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.dev2010.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2013.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.dev2012.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2013.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2012.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2014.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2013.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2011.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2011.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2014.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2010.de-en.en.xml\n",
            ".data/iwslt/de-en/train.tags.de-en.de\n",
            ".data/iwslt/de-en/train.tags.de-en.en\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('Example class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.', UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JoDj1tBfl9w"
      },
      "source": [
        "####Exercise 1.2: Build vocabulary for SRC and TRG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXootz3mevNM"
      },
      "source": [
        "SRC.build_vocab(train_data.src, min_freq=MIN_FREQ)#TODO\n",
        "TRG.build_vocab(train_data.trg, min_freq=MIN_FREQ)#TODO\n",
        "\n",
        "PAD_INDEX = TRG.vocab.stoi[PAD_TOKEN]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tETI5F57fZA5"
      },
      "source": [
        "Now, let's check how our data look"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFxdKI_WGimC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "912e284b-aca9-4daf-cc6e-c8666a64cfa2"
      },
      "source": [
        "def show_data_stats(train_data, valid_data, test_data, src_field, trg_field):\n",
        "    print(\"src vocabulary size:\", len(src_field.vocab))\n",
        "    print(\"trg vocabulary size:\", len(trg_field.vocab), \"\\n\")\n",
        "\n",
        "    print(\"Number of sentence pairs:\")\n",
        "    print('train:', len(train_data))\n",
        "    print('valid:', len(valid_data))\n",
        "    print('test:', len(test_data), \"\\n\")\n",
        "\n",
        "    print(\"Let's take a look at an exemplary pair of sentences:\")\n",
        "    print(\"src:\", \" \".join(vars(train_data[100])['src']))\n",
        "    print(\"trg:\", \" \".join(vars(train_data[100])['trg']), \"\\n\")   \n",
        "    \n",
        "show_data_stats(train_data, valid_data, test_data, SRC, TRG)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src vocabulary size: 15765\n",
            "trg vocabulary size: 13002 \n",
            "\n",
            "Number of sentence pairs:\n",
            "train: 143115\n",
            "valid: 690\n",
            "test: 963 \n",
            "\n",
            "Let's take a look at an exemplary pair of sentences:\n",
            "src: man sieht heißes wasser hier , hier , hier und hier austreten .\n",
            "trg: you see the hot water over here , here and here , coming out . \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBPa1Rn3BvIc"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdIgMQLcqge1"
      },
      "source": [
        "Below we implement a standard Encoder-Decoder architecture. The encoder returns its final states (`encoder_final`), which is used to initialize the decoder RNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUKvg_GRB0L7"
      },
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_embed, trg_embed, generator):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.trg_embed = trg_embed\n",
        "        self.generator = generator\n",
        "        \n",
        "    def forward(self, src, trg, src_mask, trg_mask, src_lengths, trg_lengths):\n",
        "        encoder_hidden, encoder_final = self.encode(src, src_mask, src_lengths)\n",
        "        return self.decode(encoder_hidden, encoder_final, src_mask, trg, trg_mask)\n",
        "    \n",
        "    def encode(self, src, src_mask, src_lengths):\n",
        "        return self.encoder(self.src_embed(src), src_mask, src_lengths)\n",
        "    \n",
        "    def decode(self, encoder_hidden, encoder_final, src_mask, trg, trg_mask,\n",
        "               decoder_hidden=None):\n",
        "        return self.decoder(self.trg_embed(trg), encoder_hidden, encoder_final,\n",
        "                            src_mask, trg_mask, hidden=decoder_hidden)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWHWIVwjrSAZ"
      },
      "source": [
        "####Exercise 2.1: Define softmax generation step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1OwLjdkB_j4"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, hidden_size, vocab_size):\n",
        "        super(Generator, self).__init__()\n",
        "        self.proj = nn.Linear(hidden_size, vocab_size, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.log_softmax(self.proj(x), dim=-1) #TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4cBuMeoCLyE"
      },
      "source": [
        "### Encoder\n",
        "\n",
        "We will implement a bi-directional GRU encoder.\n",
        "We will leverage mini-batches to speed up computations. Remember that sentences in mini-batches may be of different lenghts. PyTorch is able to deal with this by means of `pack_padded_sequence` and `pad_packed_sequence` functions, which support masking and padding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S40wCHxvtONT"
      },
      "source": [
        "####Exercise 2.2: Return a final vector of the source sentence\n",
        "\n",
        "Encoder reads a source sentence and generates hidden states. Once finished, the encoder returns a final vector, which represents the complete sentence. **It is constructed as a concatenation of the last and the first hidden states (because it is bi-directional!)**. This final vector will be used to initialize the decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRl-utHcCN_t"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.GRU(input_size, hidden_size, num_layers, \n",
        "                          batch_first=True, bidirectional=True, dropout=dropout)\n",
        "        \n",
        "    def forward(self, x, mask, lengths):\n",
        "        packed = pack_padded_sequence(x, lengths, batch_first=True)\n",
        "        output, final = self.rnn(packed)\n",
        "        output, _ = pad_packed_sequence(output, batch_first=True)\n",
        "\n",
        "        left_right_final = final[0:final.size(0):2]\n",
        "        right_left_final = final[1:final.size(0):2]\n",
        "        final = torch.cat([left_right_final, right_left_final], dim=2)#TODO\n",
        "\n",
        "        return output, final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JzJpm74CWI2"
      },
      "source": [
        "### Decoder\n",
        "\n",
        "Initial hidden state of the decoder is initialized with a projection of the encoder final state.\n",
        "In function `forward` there's a for-loop that computes the decoder hidden states one time step at a time. In training mode we use `teacher forcing` as we know the targets. In prediction time the model uses embedding of the previously predicted word and the last hidden state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB0K-P24wHOB"
      },
      "source": [
        "####Exercise 2.3: Initialize decoder conditioned on the encoder final vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry_6OqkdCX8F"
      },
      "source": [
        "class Decoder(nn.Module):    \n",
        "    def __init__(self, emb_size, hidden_size, attention, num_layers=1, dropout=0.5, bridge=True):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.attention = attention\n",
        "        self.dropout = dropout\n",
        "                 \n",
        "        self.rnn = nn.GRU(emb_size + 2*hidden_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "                 \n",
        "        # Initialization from the final encoder state\n",
        "        self.bridge = nn.Linear(2*hidden_size, hidden_size, bias=True) if bridge else None\n",
        "        self.dropout_layer = nn.Dropout(p=dropout)\n",
        "        self.pre_output_layer = nn.Linear(hidden_size + 2*hidden_size + emb_size, hidden_size, bias=False)\n",
        "        \n",
        "    def forward_step(self, prev_embed, encoder_hidden, src_mask, proj_key, hidden):\n",
        "        query = hidden[-1].unsqueeze(1)\n",
        "        context, attn_probs = self.attention(\n",
        "            query=query, proj_key=proj_key,\n",
        "            value=encoder_hidden, mask=src_mask)\n",
        "        \n",
        "        rnn_input = torch.cat([prev_embed, context], dim=2)\n",
        "        output, hidden = self.rnn(rnn_input, hidden)\n",
        "        \n",
        "        pre_output = torch.cat([prev_embed, output, context], dim=2)\n",
        "        pre_output = self.dropout_layer(pre_output)\n",
        "        pre_output = self.pre_output_layer(pre_output)\n",
        "\n",
        "        return output, hidden, pre_output\n",
        "    \n",
        "    def forward(self, trg_embed, encoder_hidden, encoder_final, \n",
        "                src_mask, trg_mask, hidden=None, max_len=None):\n",
        "        if max_len is None:\n",
        "            max_len = trg_mask.size(-1)\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(encoder_final)\n",
        "\n",
        "        proj_key = self.attention.key_layer(encoder_hidden)\n",
        "        decoder_states = []\n",
        "        pre_output_vectors = []\n",
        "        \n",
        "        for i in range(max_len):\n",
        "            prev_embed = trg_embed[:, i].unsqueeze(1)\n",
        "            output, hidden, pre_output = self.forward_step(\n",
        "              prev_embed, encoder_hidden, src_mask, proj_key, hidden)\n",
        "            decoder_states.append(output)\n",
        "            pre_output_vectors.append(pre_output)\n",
        "\n",
        "        decoder_states = torch.cat(decoder_states, dim=1)\n",
        "        pre_output_vectors = torch.cat(pre_output_vectors, dim=1)\n",
        "        return decoder_states, hidden, pre_output_vectors\n",
        "\n",
        "    def init_hidden(self, encoder_final):\n",
        "        if encoder_final is None:\n",
        "            return None\n",
        "        return torch.tanh(self.bridge(encoder_final))#TODO            \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUHKfKxUCiG9"
      },
      "source": [
        "### Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mx-B7ha32tkt"
      },
      "source": [
        "####Exercise 2.4: Compute context vector, which is the weighted sum of the encoder hidden states (values)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxKvpgzQCj_l"
      },
      "source": [
        "class AdditiveAttention(nn.Module):    \n",
        "    def __init__(self, hidden_size, key_size=None, query_size=None):\n",
        "        super(AdditiveAttention, self).__init__()\n",
        "        \n",
        "        # We assume a bi-directional encoder so key_size is 2*hidden_size\n",
        "        key_size = 2 * hidden_size if key_size is None else key_size\n",
        "        query_size = hidden_size if query_size is None else query_size\n",
        "\n",
        "        self.key_layer = nn.Linear(key_size, hidden_size, bias=False)\n",
        "        self.query_layer = nn.Linear(query_size, hidden_size, bias=False)\n",
        "        self.energy_layer = nn.Linear(hidden_size, 1, bias=False)\n",
        "\n",
        "        self.alphas = None\n",
        "        \n",
        "    def forward(self, query=None, proj_key=None, value=None, mask=None):\n",
        "        assert mask is not None, \"mask is required\"\n",
        "        query = self.query_layer(query)\n",
        "\n",
        "        scores = self.energy_layer(torch.tanh(query + proj_key))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "        scores.data.masked_fill_(mask == 0, -float('inf'))\n",
        "        \n",
        "        alphas = F.softmax(scores, dim=-1)\n",
        "        self.alphas = alphas               \n",
        "        context = torch.bmm(alphas, value)#TODO\n",
        "        \n",
        "        return context, alphas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir5DfTnzC0Wp"
      },
      "source": [
        "### Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtWc2AibCy5y"
      },
      "source": [
        "def init_model(src_vocab, tgt_vocab, emb_size=256, hidden_size=512, num_layers=1, dropout=0.1):\n",
        "    attention = AdditiveAttention(hidden_size)\n",
        "    model = EncoderDecoder(\n",
        "        Encoder(emb_size, hidden_size, num_layers=num_layers, dropout=dropout),\n",
        "        Decoder(emb_size, hidden_size, attention, num_layers=num_layers, dropout=dropout),\n",
        "        nn.Embedding(src_vocab, emb_size),\n",
        "        nn.Embedding(tgt_vocab, emb_size),\n",
        "        Generator(hidden_size, tgt_vocab))\n",
        "\n",
        "    return model.cuda() if USE_CUDA else model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayiCm0DPC7PD"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQujYfEgDCfo"
      },
      "source": [
        "### Batching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxlIR-0eC9DJ"
      },
      "source": [
        "class Batch:\n",
        "    def __init__(self, src, trg, pad_index=0):\n",
        "        \n",
        "        src, src_lengths = src\n",
        "        \n",
        "        self.src = src\n",
        "        self.src_lengths = src_lengths\n",
        "        self.src_mask = (src != pad_index).unsqueeze(-2)\n",
        "        self.nseqs = src.size(0)\n",
        "        \n",
        "        self.trg = None\n",
        "        self.trg_y = None\n",
        "        self.trg_mask = None\n",
        "        self.trg_lengths = None\n",
        "        self.ntokens = None\n",
        "\n",
        "        if trg is not None:\n",
        "            trg, trg_lengths = trg\n",
        "            self.trg = trg[:, :-1]\n",
        "            self.trg_lengths = trg_lengths\n",
        "            self.trg_y = trg[:, 1:]\n",
        "            self.trg_mask = (self.trg_y != pad_index)\n",
        "            self.ntokens = (self.trg_y != pad_index).data.sum().item()\n",
        "        \n",
        "        if USE_CUDA:\n",
        "            self.src = self.src.cuda()\n",
        "            self.src_mask = self.src_mask.cuda()\n",
        "\n",
        "            if trg is not None:\n",
        "                self.trg = self.trg.cuda()\n",
        "                self.trg_y = self.trg_y.cuda()\n",
        "                self.trg_mask = self.trg_mask.cuda()\n",
        "                "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxHU2SizGzUG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34bef302-568f-4246-b221-5fd669ce6938"
      },
      "source": [
        "train_iter = data.BucketIterator(train_data, batch_size=64, train=True, \n",
        "                                 sort_within_batch=True, \n",
        "                                 sort_key=lambda x: (len(x.src), len(x.trg)), repeat=False,\n",
        "                                 device=DEVICE)\n",
        "valid_iter = data.Iterator(valid_data, batch_size=1, train=False, sort=False, repeat=False, \n",
        "                           device=DEVICE)\n",
        "\n",
        "\n",
        "def rebatch(pad_idx, batch):\n",
        "    return Batch(batch.src, batch.trg, pad_idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py:48: UserWarning: Iterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULUqc-DsDIHk"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoNtRJSiDPiZ"
      },
      "source": [
        "def run_epoch(data_iter, model, loss_compute, print_every=50):\n",
        "    start = time.time()\n",
        "    total_tokens = 0\n",
        "    total_loss = 0\n",
        "    print_tokens = 0\n",
        "\n",
        "    for i, batch in enumerate(data_iter, 1):\n",
        "        \n",
        "        out, _, pre_output = model.forward(batch.src, batch.trg,\n",
        "                                           batch.src_mask, batch.trg_mask,\n",
        "                                           batch.src_lengths, batch.trg_lengths)\n",
        "        loss = loss_compute(pre_output, batch.trg_y, batch.nseqs)\n",
        "        total_loss += loss\n",
        "        total_tokens += batch.ntokens\n",
        "        print_tokens += batch.ntokens\n",
        "        \n",
        "        if model.training and i % print_every == 0:\n",
        "            elapsed = time.time() - start\n",
        "            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" % (i, loss / batch.nseqs, print_tokens / elapsed))\n",
        "            start = time.time()\n",
        "            print_tokens = 0\n",
        "\n",
        "    return math.exp(total_loss / float(total_tokens))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg5TrL5FDcgF"
      },
      "source": [
        "### Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yChdjDEQDeAs"
      },
      "source": [
        "class SimpleLossCompute:\n",
        "    def __init__(self, generator, criterion, opt=None):\n",
        "        self.generator = generator\n",
        "        self.criterion = criterion\n",
        "        self.opt = opt\n",
        "\n",
        "    def __call__(self, x, y, norm):\n",
        "        x = self.generator(x)\n",
        "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)),\n",
        "                              y.contiguous().view(-1))\n",
        "        loss = loss / norm\n",
        "\n",
        "        if self.opt is not None:\n",
        "            loss.backward()          \n",
        "            self.opt.step()\n",
        "            self.opt.zero_grad()\n",
        "\n",
        "        return loss.data.item() * norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcsJA-ptE6IW"
      },
      "source": [
        "### Greedy decoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABuFtq81E83u"
      },
      "source": [
        "def greedy_decode(model, src, src_mask, src_lengths, max_len=100, sos_index=1, eos_index=None):\n",
        "    with torch.no_grad():\n",
        "        encoder_hidden, encoder_final = model.encode(src, src_mask, src_lengths)\n",
        "        prev_y = torch.ones(1, 1).fill_(sos_index).type_as(src)\n",
        "        trg_mask = torch.ones_like(prev_y)\n",
        "\n",
        "    output = []\n",
        "    attention_scores = []\n",
        "    hidden = None\n",
        "\n",
        "    for i in range(max_len):\n",
        "        with torch.no_grad():\n",
        "            out, hidden, pre_output = model.decode(\n",
        "              encoder_hidden, encoder_final, src_mask,\n",
        "              prev_y, trg_mask, hidden)\n",
        "\n",
        "            prob = model.generator(pre_output[:, -1])\n",
        "\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.data.item()\n",
        "        output.append(next_word)\n",
        "        prev_y = torch.ones(1, 1).type_as(src).fill_(next_word)\n",
        "        attention_scores.append(model.decoder.attention.alphas.cpu().numpy())\n",
        "    \n",
        "    output = np.array(output)\n",
        "        \n",
        "    if eos_index is not None:\n",
        "        first_eos = np.where(output==eos_index)[0]\n",
        "        if len(first_eos) > 0:\n",
        "            output = output[:first_eos[0]]      \n",
        "    \n",
        "    return output, np.concatenate(attention_scores, axis=1)\n",
        "  \n",
        "\n",
        "def lookup_words(x, vocab=None):\n",
        "    if vocab is not None:\n",
        "        x = [vocab.itos[i] for i in x]\n",
        "\n",
        "    return [str(t) for t in x]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzHwRi_iIBQz"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRWA_TMQIDWf"
      },
      "source": [
        "def train(model, num_epochs=3, lr=0.0003, print_every=100):    \n",
        "    if USE_CUDA:\n",
        "        model.cuda()\n",
        "\n",
        "    criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=PAD_INDEX)\n",
        "    optim = torch.optim.Adam(model.parameters(), lr=lr)    \n",
        "    dev_perplexities = []\n",
        "\n",
        "    for epoch in range(num_epochs):      \n",
        "        print(\"Epoch\", epoch)\n",
        "        model.train()\n",
        "        train_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in train_iter), \n",
        "                                     model,\n",
        "                                     SimpleLossCompute(model.generator, criterion, optim),\n",
        "                                     print_every=print_every)\n",
        "        \n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            print_examples((rebatch(PAD_INDEX, x) for x in valid_iter), \n",
        "                           model, n=3, src_vocab=SRC.vocab, trg_vocab=TRG.vocab)        \n",
        "\n",
        "            dev_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in valid_iter), \n",
        "                                       model, \n",
        "                                       SimpleLossCompute(model.generator, criterion, None))\n",
        "            print(\"Validation perplexity: %f\" % dev_perplexity)\n",
        "            dev_perplexities.append(dev_perplexity)\n",
        "        \n",
        "    return dev_perplexities        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_0JLdf5FC_9"
      },
      "source": [
        "def print_examples(example_iter, model, n=2, max_len=100, \n",
        "                   sos_index=1, \n",
        "                   src_eos_index=None, \n",
        "                   trg_eos_index=None, \n",
        "                   src_vocab=None, trg_vocab=None):\n",
        "\n",
        "    model.eval()\n",
        "    count = 0\n",
        "    print()\n",
        "    \n",
        "    if src_vocab is not None and trg_vocab is not None:\n",
        "        src_eos_index = src_vocab.stoi[EOS_TOKEN]\n",
        "        trg_sos_index = trg_vocab.stoi[SOS_TOKEN]\n",
        "        trg_eos_index = trg_vocab.stoi[EOS_TOKEN]\n",
        "    else:\n",
        "        src_eos_index = None\n",
        "        trg_sos_index = 1\n",
        "        trg_eos_index = None\n",
        "        \n",
        "    for i, batch in enumerate(example_iter):\n",
        "      \n",
        "        src = batch.src.cpu().numpy()[0, :]\n",
        "        trg = batch.trg_y.cpu().numpy()[0, :]\n",
        "\n",
        "        src = src[:-1] if src[-1] == src_eos_index else src\n",
        "        trg = trg[:-1] if trg[-1] == trg_eos_index else trg      \n",
        "      \n",
        "        result, _ = greedy_decode(\n",
        "          model, batch.src, batch.src_mask, batch.src_lengths,\n",
        "          max_len=max_len, sos_index=trg_sos_index, eos_index=trg_eos_index)\n",
        "        print(\"Example #%d\" % (i+1))\n",
        "        print(\"Src : \", \" \".join(lookup_words(src, vocab=src_vocab)))\n",
        "        print(\"Trg : \", \" \".join(lookup_words(trg, vocab=trg_vocab)))\n",
        "        print(\"Pred: \", \" \".join(lookup_words(result, vocab=trg_vocab)))\n",
        "        print()\n",
        "        \n",
        "        count += 1\n",
        "        if count == n:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHkSsR7GI50z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc700c4-d62d-4266-a0af-906a638f04a5"
      },
      "source": [
        "model = init_model(len(SRC.vocab), len(TRG.vocab),\n",
        "                   emb_size=256, hidden_size=256,\n",
        "                   num_layers=1, dropout=0.2)\n",
        "dev_perplexities = train(model, print_every=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch Step: 100 Loss: 42.903297 Tokens per Sec: 22079.310911\n",
            "Epoch Step: 200 Loss: 37.614697 Tokens per Sec: 24819.098881\n",
            "Epoch Step: 300 Loss: 11.525517 Tokens per Sec: 24368.179367\n",
            "Epoch Step: 400 Loss: 63.212666 Tokens per Sec: 24858.623447\n",
            "Epoch Step: 500 Loss: 42.506031 Tokens per Sec: 25640.007368\n",
            "Epoch Step: 600 Loss: 64.898048 Tokens per Sec: 24686.008223\n",
            "Epoch Step: 700 Loss: 54.803696 Tokens per Sec: 23705.350155\n",
            "Epoch Step: 800 Loss: 77.154495 Tokens per Sec: 25198.702859\n",
            "Epoch Step: 900 Loss: 96.389854 Tokens per Sec: 25145.949197\n",
            "Epoch Step: 1000 Loss: 53.864231 Tokens per Sec: 24869.382952\n",
            "Epoch Step: 1100 Loss: 16.770924 Tokens per Sec: 24976.808297\n",
            "Epoch Step: 1200 Loss: 28.194580 Tokens per Sec: 24485.331220\n",
            "Epoch Step: 1300 Loss: 65.433876 Tokens per Sec: 24977.469036\n",
            "Epoch Step: 1400 Loss: 94.230202 Tokens per Sec: 25289.855442\n",
            "Epoch Step: 1500 Loss: 28.247158 Tokens per Sec: 24822.045414\n",
            "Epoch Step: 1600 Loss: 20.518684 Tokens per Sec: 24469.769542\n",
            "Epoch Step: 1700 Loss: 80.181473 Tokens per Sec: 25845.173439\n",
            "Epoch Step: 1800 Loss: 64.816612 Tokens per Sec: 25642.971189\n",
            "Epoch Step: 1900 Loss: 38.462540 Tokens per Sec: 25218.167962\n",
            "Epoch Step: 2000 Loss: 46.688610 Tokens per Sec: 23837.838783\n",
            "Epoch Step: 2100 Loss: 53.035656 Tokens per Sec: 24589.388742\n",
            "Epoch Step: 2200 Loss: 15.155299 Tokens per Sec: 24148.347178\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 15 years ago , i was a <unk> of the <unk> of the <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father was on the way , the <unk> , the <unk> of the <unk> .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he was very much , and what was really interesting , what was really , the first time , the first time .\n",
            "\n",
            "Validation perplexity: 30.424749\n",
            "Epoch 1\n",
            "Epoch Step: 100 Loss: 40.417938 Tokens per Sec: 22140.209146\n",
            "Epoch Step: 200 Loss: 39.389664 Tokens per Sec: 24249.722282\n",
            "Epoch Step: 300 Loss: 55.796860 Tokens per Sec: 23435.175098\n",
            "Epoch Step: 400 Loss: 71.875221 Tokens per Sec: 25289.895857\n",
            "Epoch Step: 500 Loss: 63.273235 Tokens per Sec: 24412.398587\n",
            "Epoch Step: 600 Loss: 82.109444 Tokens per Sec: 22541.853261\n",
            "Epoch Step: 700 Loss: 80.509583 Tokens per Sec: 25218.573405\n",
            "Epoch Step: 800 Loss: 41.679173 Tokens per Sec: 24291.832820\n",
            "Epoch Step: 900 Loss: 48.513428 Tokens per Sec: 25015.420334\n",
            "Epoch Step: 1000 Loss: 45.222973 Tokens per Sec: 25469.567246\n",
            "Epoch Step: 1100 Loss: 12.738090 Tokens per Sec: 24688.962181\n",
            "Epoch Step: 1200 Loss: 29.585512 Tokens per Sec: 25324.409813\n",
            "Epoch Step: 1300 Loss: 19.407276 Tokens per Sec: 25444.789672\n",
            "Epoch Step: 1400 Loss: 38.134686 Tokens per Sec: 23990.227196\n",
            "Epoch Step: 1500 Loss: 46.580967 Tokens per Sec: 25252.049168\n",
            "Epoch Step: 1600 Loss: 27.352892 Tokens per Sec: 24999.741655\n",
            "Epoch Step: 1700 Loss: 53.671150 Tokens per Sec: 24499.064879\n",
            "Epoch Step: 1800 Loss: 18.347609 Tokens per Sec: 24661.722055\n",
            "Epoch Step: 1900 Loss: 4.645948 Tokens per Sec: 24712.979856\n",
            "Epoch Step: 2000 Loss: 63.701687 Tokens per Sec: 25293.372533\n",
            "Epoch Step: 2100 Loss: 81.657288 Tokens per Sec: 23787.042894\n",
            "Epoch Step: 2200 Loss: 24.148880 Tokens per Sec: 24483.623301\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was a <unk> of the <unk> of the <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father was on his little <unk> , the <unk> of the <unk> .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy , which was pretty much , it was a very much of <unk> .\n",
            "\n",
            "Validation perplexity: 19.335134\n",
            "Epoch 2\n",
            "Epoch Step: 100 Loss: 34.388218 Tokens per Sec: 23859.760946\n",
            "Epoch Step: 200 Loss: 73.314514 Tokens per Sec: 25395.497742\n",
            "Epoch Step: 300 Loss: 44.650021 Tokens per Sec: 24482.428995\n",
            "Epoch Step: 400 Loss: 13.260446 Tokens per Sec: 25239.204731\n",
            "Epoch Step: 500 Loss: 66.105865 Tokens per Sec: 23186.246855\n",
            "Epoch Step: 600 Loss: 37.536533 Tokens per Sec: 24083.785460\n",
            "Epoch Step: 700 Loss: 19.313425 Tokens per Sec: 24905.030380\n",
            "Epoch Step: 800 Loss: 33.818810 Tokens per Sec: 23968.587415\n",
            "Epoch Step: 900 Loss: 29.699495 Tokens per Sec: 25518.686308\n",
            "Epoch Step: 1000 Loss: 12.094456 Tokens per Sec: 24848.826643\n",
            "Epoch Step: 1100 Loss: 46.787479 Tokens per Sec: 25236.154600\n",
            "Epoch Step: 1200 Loss: 46.755280 Tokens per Sec: 25173.215564\n",
            "Epoch Step: 1300 Loss: 16.310759 Tokens per Sec: 24361.870105\n",
            "Epoch Step: 1400 Loss: 28.812607 Tokens per Sec: 24326.952339\n",
            "Epoch Step: 1500 Loss: 30.337280 Tokens per Sec: 25267.166926\n",
            "Epoch Step: 1600 Loss: 23.684181 Tokens per Sec: 25467.303990\n",
            "Epoch Step: 1700 Loss: 32.927986 Tokens per Sec: 25369.287148\n",
            "Epoch Step: 1800 Loss: 74.805359 Tokens per Sec: 25051.270078\n",
            "Epoch Step: 1900 Loss: 14.420730 Tokens per Sec: 24219.913425\n",
            "Epoch Step: 2000 Loss: 13.148981 Tokens per Sec: 25344.688792\n",
            "Epoch Step: 2100 Loss: 71.778999 Tokens per Sec: 25492.971262\n",
            "Epoch Step: 2200 Loss: 23.262640 Tokens per Sec: 25485.610139\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was a <unk> of the <unk> of the <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father was on his little boy , the <unk> of the bbc of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy , which was pretty much , was the <unk> of the <unk> of <unk> .\n",
            "\n",
            "Validation perplexity: 15.113349\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDm8NDJ8I_hX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "5aa9d84e-7dee-4190-d178-bb5ee55bd17e"
      },
      "source": [
        "def plot_perplexity(perplexities):\n",
        "    \"\"\"plot perplexities\"\"\"\n",
        "    plt.title(\"Perplexity per Epoch\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Perplexity\")\n",
        "    plt.plot(perplexities)\n",
        "    \n",
        "plot_perplexity(dev_perplexities)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06eFV1ArFBNa"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWlpkgMMJMgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50702a44-29d1-4a89-f23e-4711ebbc3322"
      },
      "source": [
        "!pip install sacrebleu\n",
        "import sacrebleu\n",
        "\n",
        "hypotheses = [\"this is a test\"]\n",
        "references = [\"this is a evaluation\"]\n",
        "bleu = sacrebleu.raw_corpus_bleu(hypotheses, [references], .01).score\n",
        "print(bleu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (1.4.14)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.6/dist-packages (from sacrebleu) (2.0.0)\n",
            "22.360679774997894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fitRnpp8Sxq9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcbb953d-3e0f-4df3-d7bd-1a7e4d447e4b"
      },
      "source": [
        "len(valid_data)\n",
        "references = [\" \".join(example.trg) for example in valid_data]\n",
        "print(len(references))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgZTyWy1NxqI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "570d7250-0580-4aaa-d131-5805a1748916"
      },
      "source": [
        "hypotheses = []\n",
        "alphas = []  # attention scores\n",
        "for batch in valid_iter:\n",
        "  batch = rebatch(PAD_INDEX, batch)\n",
        "  pred, attention = greedy_decode(\n",
        "    model, batch.src, batch.src_mask, batch.src_lengths, max_len=25,\n",
        "    sos_index=TRG.vocab.stoi[SOS_TOKEN],\n",
        "    eos_index=TRG.vocab.stoi[EOS_TOKEN])\n",
        "  hypotheses.append(pred)\n",
        "  alphas.append(attention)\n",
        "hypotheses = [lookup_words(x, TRG.vocab) for x in hypotheses]\n",
        "hypotheses = [\" \".join(x) for x in hypotheses]\n",
        "\n",
        "assert(len(hypotheses) == len(references))\n",
        "\n",
        "bleu = sacrebleu.raw_corpus_bleu(hypotheses, [references], .01).score\n",
        "print(bleu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
            "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "19.369174654083444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT4GJA2KM85x"
      },
      "source": [
        "### Visualization of Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_iss3EANA5S"
      },
      "source": [
        "def plot_heatmap(src, trg, scores):\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    heatmap = ax.pcolor(scores, cmap='viridis')\n",
        "    ax.set_xticklabels(trg, minor=False, rotation='vertical')\n",
        "    ax.set_yticklabels(src, minor=False)\n",
        "    ax.xaxis.tick_top()\n",
        "    ax.set_xticks(np.arange(scores.shape[1]) + 0.5, minor=False)\n",
        "    ax.set_yticks(np.arange(scores.shape[0]) + 0.5, minor=False)\n",
        "    ax.invert_yaxis()\n",
        "    plt.colorbar(heatmap)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP1uUDg2NC2U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "2427b735-1358-4dcf-bb5d-dc8a86a8d48d"
      },
      "source": [
        "idx = 5\n",
        "src = valid_data[idx].src + [\"</s>\"]\n",
        "trg = valid_data[idx].trg + [\"</s>\"]\n",
        "pred = hypotheses[idx].split() + [\"</s>\"]\n",
        "pred_att = alphas[idx][0].T[:, :len(pred)]\n",
        "print(\"src\", src)\n",
        "print(\"ref\", trg)\n",
        "print(\"pred\", pred)\n",
        "plot_heatmap(src, pred, pred_att)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src ['\"', 'jetzt', 'kannst', 'du', 'auf', 'eine', 'richtige', 'schule', 'gehen', ',', '\"', 'sagte', 'er', '.', '</s>']\n",
            "ref ['\"', 'you', 'can', 'go', 'to', 'a', 'real', 'school', 'now', ',', '\"', 'he', 'said', '.', '</s>']\n",
            "pred ['\"', 'now', 'you', 'can', 'go', 'to', 'a', 'right', 'school', ',', '\"', 'he', 'said', '.', '</s>']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlPu4yuWUCMo"
      },
      "source": [
        "## Wrap-up\n",
        "\n",
        "Now you know all the nitty-gritty of the Encoder-Decoder architecture implemented using RNNs and attention mechanism. \n",
        "\n",
        "Here are some suggestions how to improve the model:\n",
        "- train for more epochs (now `num_epochs` is set to 3 but you can try with for example `num_epochs=10` and see if the perplexity and bleu scores improve)\n",
        "- use BPEs\n",
        "- use beam search instead of greedy decoding\n",
        "- add more layers to encoder/decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnHtMivwGSpB"
      },
      "source": [
        "## References\n",
        "* BPE - [paper](https://arxiv.org/abs/1508.07909) and [code](https://github.com/rsennrich/subword-nmt)\n",
        "* BLEU - [paper](https://www.aclweb.org/anthology/P02-1040/) and [code](https://github.com/moses-smt/mosesdecoder/blob/master/scripts/generic/multi-bleu.perl)\n",
        "* Attention - [additive](https://arxiv.org/abs/1409.0473) and [multiplicative](https://arxiv.org/abs/1508.04025)\n"
      ]
    }
  ]
}